{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络算法-相分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "脚本路径下所需文件：<span style=\"color: yellow; font-size: 20px;\">1.</span>本脚本<span style=\"color: yellow; font-size: 20px;\">2.</span>数据集Phase_clean_data.xlsx<span style=\"color: yellow; font-size: 20px;\">3.</span>筛选出的<span style=\"color: green; font-size: 20px;\">alloy_selected.csv</span>文件<span style=\"color: yellow; font-size: 20px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据导入，处理为张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_excel(\"Phase_clean_data.xlsx\", sheet_name=\"Sheet1\")\n",
    "y = df[[\"FCC\", \"BCC\", \"IM\", \"AM\"]].values  # 目标标签\n",
    "X = df.drop([\"FCC\", \"BCC\", \"IM\", \"AM\"], axis=1).values  # 特征\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 转换为Tensor\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 创建DataLoader（批量加载数据）\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 根据数据集类别差异更新权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0331, 0.0367, 0.0402, 0.8901])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 计算类别权重\n",
    "class_counts = np.sum(y_train, axis=0)  #axis=0,行方向压缩数组求和\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights / np.sum(class_weights)\n",
    "weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 定义3个对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phaseclassifier(\n",
      "  (fc1): Linear(in_features=20, out_features=128, bias=True)\n",
      "  (dropout1): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (dropout2): Dropout(p=0.3, inplace=False)\n",
      "  (out): Linear(in_features=64, out_features=4, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义模型\n",
    "class phaseclassifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size):   #网络结构\n",
    "        super(phaseclassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(64, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):          #正向传播\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.out(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "# 初始化模型\n",
    "model = phaseclassifier(input_size=X_train.shape[1],output_size=y_train.shape[1])     #输入维度（特征数量）,输出维度（预测标签数）\n",
    "print(model)\n",
    "\n",
    "\n",
    "# 定义损失函数与优化器\n",
    "criterion = nn.BCELoss(weight=weights)  # 二元交叉熵损失，根据类别频率调整权重\n",
    "optimizer = optim.Adam(model.parameters(),  #修改所有参数\n",
    "                        lr=0.001            #学习率\n",
    "                      )           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 定义训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs, patience):\n",
    "    #用于计算损失\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    #用于早停计数\n",
    "    no_improve_epochs = 0\n",
    "    \n",
    "    # 用于保存最佳模型预测结果（概率和真实标签）\n",
    "    best_model_outputs = None\n",
    "    best_model_labels = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        sum_train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_train_loss += loss.item() * inputs.size(0)\n",
    "        avg_train_loss = sum_train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        sum_val_loss = 0.0\n",
    "        all_outputs, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                sum_val_loss += loss.item() * inputs.size(0)\n",
    "                all_outputs.append(outputs.cpu())\n",
    "                all_labels.append(labels.cpu())\n",
    "        avg_val_loss = sum_val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # 早停判断\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            no_improve_epochs = 0\n",
    "            # 保存当前最佳模型的输出和标签\n",
    "            best_model_outputs = torch.cat(all_outputs, dim=0)\n",
    "            best_model_labels = torch.cat(all_labels, dim=0)\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            if no_improve_epochs >= patience:\n",
    "                print(f\"早停步 epoch= {epoch+1}\")\n",
    "                break\n",
    "\n",
    "\n",
    "        # 打印日志\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    print(\"训练完成\")\n",
    "    return train_losses, val_losses, best_model_outputs, best_model_labels, epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 网格搜索早停防止过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 网格搜索 patience=5 ===\n",
      "Epoch 1/500 | Train Loss: 0.1530 | Val Loss: 0.1296\n",
      "Epoch 2/500 | Train Loss: 0.1032 | Val Loss: 0.0770\n",
      "Epoch 3/500 | Train Loss: 0.0561 | Val Loss: 0.0511\n",
      "Epoch 4/500 | Train Loss: 0.0435 | Val Loss: 0.0484\n",
      "Epoch 5/500 | Train Loss: 0.0389 | Val Loss: 0.0455\n",
      "Epoch 6/500 | Train Loss: 0.0382 | Val Loss: 0.0421\n",
      "Epoch 7/500 | Train Loss: 0.0362 | Val Loss: 0.0388\n",
      "Epoch 8/500 | Train Loss: 0.0338 | Val Loss: 0.0353\n",
      "Epoch 9/500 | Train Loss: 0.0313 | Val Loss: 0.0330\n",
      "Epoch 10/500 | Train Loss: 0.0316 | Val Loss: 0.0302\n",
      "Epoch 11/500 | Train Loss: 0.0284 | Val Loss: 0.0282\n",
      "Epoch 12/500 | Train Loss: 0.0277 | Val Loss: 0.0263\n",
      "Epoch 13/500 | Train Loss: 0.0254 | Val Loss: 0.0252\n",
      "Epoch 14/500 | Train Loss: 0.0259 | Val Loss: 0.0242\n",
      "Epoch 15/500 | Train Loss: 0.0247 | Val Loss: 0.0238\n",
      "Epoch 16/500 | Train Loss: 0.0237 | Val Loss: 0.0231\n",
      "Epoch 17/500 | Train Loss: 0.0240 | Val Loss: 0.0225\n",
      "Epoch 18/500 | Train Loss: 0.0231 | Val Loss: 0.0224\n",
      "Epoch 19/500 | Train Loss: 0.0234 | Val Loss: 0.0221\n",
      "Epoch 20/500 | Train Loss: 0.0230 | Val Loss: 0.0220\n",
      "Epoch 21/500 | Train Loss: 0.0226 | Val Loss: 0.0218\n",
      "Epoch 22/500 | Train Loss: 0.0224 | Val Loss: 0.0218\n",
      "Epoch 23/500 | Train Loss: 0.0223 | Val Loss: 0.0213\n",
      "Epoch 24/500 | Train Loss: 0.0217 | Val Loss: 0.0212\n",
      "Epoch 25/500 | Train Loss: 0.0214 | Val Loss: 0.0210\n",
      "Epoch 26/500 | Train Loss: 0.0215 | Val Loss: 0.0211\n",
      "Epoch 27/500 | Train Loss: 0.0209 | Val Loss: 0.0211\n",
      "Epoch 28/500 | Train Loss: 0.0219 | Val Loss: 0.0208\n",
      "Epoch 29/500 | Train Loss: 0.0212 | Val Loss: 0.0208\n",
      "Epoch 30/500 | Train Loss: 0.0209 | Val Loss: 0.0206\n",
      "Epoch 31/500 | Train Loss: 0.0211 | Val Loss: 0.0205\n",
      "Epoch 32/500 | Train Loss: 0.0201 | Val Loss: 0.0206\n",
      "Epoch 33/500 | Train Loss: 0.0204 | Val Loss: 0.0203\n",
      "Epoch 34/500 | Train Loss: 0.0203 | Val Loss: 0.0204\n",
      "Epoch 35/500 | Train Loss: 0.0209 | Val Loss: 0.0204\n",
      "Epoch 36/500 | Train Loss: 0.0201 | Val Loss: 0.0202\n",
      "Epoch 37/500 | Train Loss: 0.0202 | Val Loss: 0.0202\n",
      "Epoch 38/500 | Train Loss: 0.0198 | Val Loss: 0.0201\n",
      "Epoch 39/500 | Train Loss: 0.0204 | Val Loss: 0.0201\n",
      "Epoch 40/500 | Train Loss: 0.0199 | Val Loss: 0.0200\n",
      "Epoch 41/500 | Train Loss: 0.0198 | Val Loss: 0.0200\n",
      "Epoch 42/500 | Train Loss: 0.0198 | Val Loss: 0.0200\n",
      "Epoch 43/500 | Train Loss: 0.0196 | Val Loss: 0.0199\n",
      "Epoch 44/500 | Train Loss: 0.0189 | Val Loss: 0.0199\n",
      "Epoch 45/500 | Train Loss: 0.0194 | Val Loss: 0.0197\n",
      "Epoch 46/500 | Train Loss: 0.0187 | Val Loss: 0.0195\n",
      "Epoch 47/500 | Train Loss: 0.0193 | Val Loss: 0.0195\n",
      "Epoch 48/500 | Train Loss: 0.0200 | Val Loss: 0.0195\n",
      "Epoch 49/500 | Train Loss: 0.0190 | Val Loss: 0.0195\n",
      "Epoch 50/500 | Train Loss: 0.0189 | Val Loss: 0.0195\n",
      "Epoch 51/500 | Train Loss: 0.0185 | Val Loss: 0.0193\n",
      "Epoch 52/500 | Train Loss: 0.0181 | Val Loss: 0.0192\n",
      "Epoch 53/500 | Train Loss: 0.0182 | Val Loss: 0.0191\n",
      "Epoch 54/500 | Train Loss: 0.0186 | Val Loss: 0.0192\n",
      "Epoch 55/500 | Train Loss: 0.0179 | Val Loss: 0.0189\n",
      "Epoch 56/500 | Train Loss: 0.0186 | Val Loss: 0.0190\n",
      "Epoch 57/500 | Train Loss: 0.0177 | Val Loss: 0.0188\n",
      "Epoch 58/500 | Train Loss: 0.0178 | Val Loss: 0.0188\n",
      "Epoch 59/500 | Train Loss: 0.0181 | Val Loss: 0.0187\n",
      "Epoch 60/500 | Train Loss: 0.0182 | Val Loss: 0.0187\n",
      "Epoch 61/500 | Train Loss: 0.0176 | Val Loss: 0.0185\n",
      "Epoch 62/500 | Train Loss: 0.0179 | Val Loss: 0.0185\n",
      "Epoch 63/500 | Train Loss: 0.0178 | Val Loss: 0.0184\n",
      "Epoch 64/500 | Train Loss: 0.0178 | Val Loss: 0.0185\n",
      "Epoch 65/500 | Train Loss: 0.0174 | Val Loss: 0.0183\n",
      "Epoch 66/500 | Train Loss: 0.0172 | Val Loss: 0.0182\n",
      "Epoch 67/500 | Train Loss: 0.0171 | Val Loss: 0.0181\n",
      "Epoch 68/500 | Train Loss: 0.0170 | Val Loss: 0.0179\n",
      "Epoch 69/500 | Train Loss: 0.0167 | Val Loss: 0.0179\n",
      "Epoch 70/500 | Train Loss: 0.0171 | Val Loss: 0.0178\n",
      "Epoch 71/500 | Train Loss: 0.0169 | Val Loss: 0.0179\n",
      "Epoch 72/500 | Train Loss: 0.0172 | Val Loss: 0.0180\n",
      "Epoch 73/500 | Train Loss: 0.0174 | Val Loss: 0.0179\n",
      "Epoch 74/500 | Train Loss: 0.0168 | Val Loss: 0.0177\n",
      "Epoch 75/500 | Train Loss: 0.0172 | Val Loss: 0.0177\n",
      "Epoch 76/500 | Train Loss: 0.0166 | Val Loss: 0.0177\n",
      "Epoch 77/500 | Train Loss: 0.0167 | Val Loss: 0.0176\n",
      "Epoch 78/500 | Train Loss: 0.0170 | Val Loss: 0.0176\n",
      "Epoch 79/500 | Train Loss: 0.0163 | Val Loss: 0.0176\n",
      "Epoch 80/500 | Train Loss: 0.0161 | Val Loss: 0.0174\n",
      "Epoch 81/500 | Train Loss: 0.0167 | Val Loss: 0.0175\n",
      "Epoch 82/500 | Train Loss: 0.0166 | Val Loss: 0.0175\n",
      "Epoch 83/500 | Train Loss: 0.0160 | Val Loss: 0.0173\n",
      "Epoch 84/500 | Train Loss: 0.0160 | Val Loss: 0.0173\n",
      "Epoch 85/500 | Train Loss: 0.0163 | Val Loss: 0.0173\n",
      "Epoch 86/500 | Train Loss: 0.0163 | Val Loss: 0.0173\n",
      "Epoch 87/500 | Train Loss: 0.0161 | Val Loss: 0.0172\n",
      "Epoch 88/500 | Train Loss: 0.0163 | Val Loss: 0.0171\n",
      "Epoch 89/500 | Train Loss: 0.0164 | Val Loss: 0.0173\n",
      "Epoch 90/500 | Train Loss: 0.0162 | Val Loss: 0.0172\n",
      "Epoch 91/500 | Train Loss: 0.0158 | Val Loss: 0.0171\n",
      "Epoch 92/500 | Train Loss: 0.0157 | Val Loss: 0.0171\n",
      "Epoch 93/500 | Train Loss: 0.0160 | Val Loss: 0.0170\n",
      "Epoch 94/500 | Train Loss: 0.0156 | Val Loss: 0.0169\n",
      "Epoch 95/500 | Train Loss: 0.0157 | Val Loss: 0.0169\n",
      "Epoch 96/500 | Train Loss: 0.0162 | Val Loss: 0.0168\n",
      "Epoch 97/500 | Train Loss: 0.0156 | Val Loss: 0.0168\n",
      "Epoch 98/500 | Train Loss: 0.0160 | Val Loss: 0.0168\n",
      "Epoch 99/500 | Train Loss: 0.0153 | Val Loss: 0.0168\n",
      "Epoch 100/500 | Train Loss: 0.0153 | Val Loss: 0.0167\n",
      "Epoch 101/500 | Train Loss: 0.0153 | Val Loss: 0.0167\n",
      "Epoch 102/500 | Train Loss: 0.0154 | Val Loss: 0.0167\n",
      "Epoch 103/500 | Train Loss: 0.0152 | Val Loss: 0.0166\n",
      "Epoch 104/500 | Train Loss: 0.0150 | Val Loss: 0.0166\n",
      "Epoch 105/500 | Train Loss: 0.0153 | Val Loss: 0.0165\n",
      "Epoch 106/500 | Train Loss: 0.0154 | Val Loss: 0.0166\n",
      "Epoch 107/500 | Train Loss: 0.0151 | Val Loss: 0.0166\n",
      "Epoch 108/500 | Train Loss: 0.0157 | Val Loss: 0.0164\n",
      "Epoch 109/500 | Train Loss: 0.0151 | Val Loss: 0.0164\n",
      "Epoch 110/500 | Train Loss: 0.0153 | Val Loss: 0.0164\n",
      "Epoch 111/500 | Train Loss: 0.0149 | Val Loss: 0.0163\n",
      "Epoch 112/500 | Train Loss: 0.0155 | Val Loss: 0.0161\n",
      "Epoch 113/500 | Train Loss: 0.0149 | Val Loss: 0.0163\n",
      "Epoch 114/500 | Train Loss: 0.0149 | Val Loss: 0.0163\n",
      "Epoch 115/500 | Train Loss: 0.0159 | Val Loss: 0.0162\n",
      "Epoch 116/500 | Train Loss: 0.0149 | Val Loss: 0.0162\n",
      "Epoch 117/500 | Train Loss: 0.0147 | Val Loss: 0.0161\n",
      "Epoch 118/500 | Train Loss: 0.0153 | Val Loss: 0.0160\n",
      "Epoch 119/500 | Train Loss: 0.0147 | Val Loss: 0.0161\n",
      "Epoch 120/500 | Train Loss: 0.0145 | Val Loss: 0.0159\n",
      "Epoch 121/500 | Train Loss: 0.0148 | Val Loss: 0.0159\n",
      "Epoch 122/500 | Train Loss: 0.0149 | Val Loss: 0.0160\n",
      "Epoch 123/500 | Train Loss: 0.0145 | Val Loss: 0.0161\n",
      "Epoch 124/500 | Train Loss: 0.0151 | Val Loss: 0.0161\n",
      "Epoch 125/500 | Train Loss: 0.0151 | Val Loss: 0.0160\n",
      "早停步 epoch= 126\n",
      "训练完成\n",
      "=== 网格搜索 patience=10 ===\n",
      "Epoch 1/500 | Train Loss: 0.1527 | Val Loss: 0.1291\n",
      "Epoch 2/500 | Train Loss: 0.1020 | Val Loss: 0.0761\n",
      "Epoch 3/500 | Train Loss: 0.0565 | Val Loss: 0.0511\n",
      "Epoch 4/500 | Train Loss: 0.0427 | Val Loss: 0.0479\n",
      "Epoch 5/500 | Train Loss: 0.0394 | Val Loss: 0.0458\n",
      "Epoch 6/500 | Train Loss: 0.0382 | Val Loss: 0.0425\n",
      "Epoch 7/500 | Train Loss: 0.0364 | Val Loss: 0.0388\n",
      "Epoch 8/500 | Train Loss: 0.0335 | Val Loss: 0.0356\n",
      "Epoch 9/500 | Train Loss: 0.0325 | Val Loss: 0.0325\n",
      "Epoch 10/500 | Train Loss: 0.0296 | Val Loss: 0.0301\n",
      "Epoch 11/500 | Train Loss: 0.0298 | Val Loss: 0.0282\n",
      "Epoch 12/500 | Train Loss: 0.0269 | Val Loss: 0.0265\n",
      "Epoch 13/500 | Train Loss: 0.0263 | Val Loss: 0.0253\n",
      "Epoch 14/500 | Train Loss: 0.0255 | Val Loss: 0.0248\n",
      "Epoch 15/500 | Train Loss: 0.0238 | Val Loss: 0.0240\n",
      "Epoch 16/500 | Train Loss: 0.0248 | Val Loss: 0.0236\n",
      "Epoch 17/500 | Train Loss: 0.0237 | Val Loss: 0.0232\n",
      "Epoch 18/500 | Train Loss: 0.0235 | Val Loss: 0.0226\n",
      "Epoch 19/500 | Train Loss: 0.0237 | Val Loss: 0.0226\n",
      "Epoch 20/500 | Train Loss: 0.0234 | Val Loss: 0.0221\n",
      "Epoch 21/500 | Train Loss: 0.0227 | Val Loss: 0.0223\n",
      "Epoch 22/500 | Train Loss: 0.0225 | Val Loss: 0.0220\n",
      "Epoch 23/500 | Train Loss: 0.0221 | Val Loss: 0.0217\n",
      "Epoch 24/500 | Train Loss: 0.0216 | Val Loss: 0.0215\n",
      "Epoch 25/500 | Train Loss: 0.0223 | Val Loss: 0.0215\n",
      "Epoch 26/500 | Train Loss: 0.0216 | Val Loss: 0.0213\n",
      "Epoch 27/500 | Train Loss: 0.0214 | Val Loss: 0.0212\n",
      "Epoch 28/500 | Train Loss: 0.0214 | Val Loss: 0.0210\n",
      "Epoch 29/500 | Train Loss: 0.0212 | Val Loss: 0.0208\n",
      "Epoch 30/500 | Train Loss: 0.0211 | Val Loss: 0.0208\n",
      "Epoch 31/500 | Train Loss: 0.0207 | Val Loss: 0.0208\n",
      "Epoch 32/500 | Train Loss: 0.0207 | Val Loss: 0.0208\n",
      "Epoch 33/500 | Train Loss: 0.0206 | Val Loss: 0.0206\n",
      "Epoch 34/500 | Train Loss: 0.0204 | Val Loss: 0.0207\n",
      "Epoch 35/500 | Train Loss: 0.0214 | Val Loss: 0.0205\n",
      "Epoch 36/500 | Train Loss: 0.0202 | Val Loss: 0.0205\n",
      "Epoch 37/500 | Train Loss: 0.0198 | Val Loss: 0.0203\n",
      "Epoch 38/500 | Train Loss: 0.0207 | Val Loss: 0.0203\n",
      "Epoch 39/500 | Train Loss: 0.0201 | Val Loss: 0.0201\n",
      "Epoch 40/500 | Train Loss: 0.0194 | Val Loss: 0.0201\n",
      "Epoch 41/500 | Train Loss: 0.0196 | Val Loss: 0.0199\n",
      "Epoch 42/500 | Train Loss: 0.0199 | Val Loss: 0.0201\n",
      "Epoch 43/500 | Train Loss: 0.0203 | Val Loss: 0.0200\n",
      "Epoch 44/500 | Train Loss: 0.0196 | Val Loss: 0.0199\n",
      "Epoch 45/500 | Train Loss: 0.0199 | Val Loss: 0.0198\n",
      "Epoch 46/500 | Train Loss: 0.0193 | Val Loss: 0.0199\n",
      "Epoch 47/500 | Train Loss: 0.0198 | Val Loss: 0.0197\n",
      "Epoch 48/500 | Train Loss: 0.0191 | Val Loss: 0.0197\n",
      "Epoch 49/500 | Train Loss: 0.0190 | Val Loss: 0.0196\n",
      "Epoch 50/500 | Train Loss: 0.0190 | Val Loss: 0.0195\n",
      "Epoch 51/500 | Train Loss: 0.0185 | Val Loss: 0.0195\n",
      "Epoch 52/500 | Train Loss: 0.0185 | Val Loss: 0.0193\n",
      "Epoch 53/500 | Train Loss: 0.0190 | Val Loss: 0.0193\n",
      "Epoch 54/500 | Train Loss: 0.0185 | Val Loss: 0.0193\n",
      "Epoch 55/500 | Train Loss: 0.0185 | Val Loss: 0.0192\n",
      "Epoch 56/500 | Train Loss: 0.0184 | Val Loss: 0.0191\n",
      "Epoch 57/500 | Train Loss: 0.0176 | Val Loss: 0.0191\n",
      "Epoch 58/500 | Train Loss: 0.0182 | Val Loss: 0.0190\n",
      "Epoch 59/500 | Train Loss: 0.0180 | Val Loss: 0.0188\n",
      "Epoch 60/500 | Train Loss: 0.0180 | Val Loss: 0.0187\n",
      "Epoch 61/500 | Train Loss: 0.0179 | Val Loss: 0.0190\n",
      "Epoch 62/500 | Train Loss: 0.0176 | Val Loss: 0.0188\n",
      "Epoch 63/500 | Train Loss: 0.0180 | Val Loss: 0.0186\n",
      "Epoch 64/500 | Train Loss: 0.0177 | Val Loss: 0.0186\n",
      "Epoch 65/500 | Train Loss: 0.0177 | Val Loss: 0.0184\n",
      "Epoch 66/500 | Train Loss: 0.0178 | Val Loss: 0.0183\n",
      "Epoch 67/500 | Train Loss: 0.0169 | Val Loss: 0.0184\n",
      "Epoch 68/500 | Train Loss: 0.0172 | Val Loss: 0.0182\n",
      "Epoch 69/500 | Train Loss: 0.0169 | Val Loss: 0.0181\n",
      "Epoch 70/500 | Train Loss: 0.0169 | Val Loss: 0.0180\n",
      "Epoch 71/500 | Train Loss: 0.0174 | Val Loss: 0.0180\n",
      "Epoch 72/500 | Train Loss: 0.0168 | Val Loss: 0.0179\n",
      "Epoch 73/500 | Train Loss: 0.0168 | Val Loss: 0.0180\n",
      "Epoch 74/500 | Train Loss: 0.0168 | Val Loss: 0.0179\n",
      "Epoch 75/500 | Train Loss: 0.0165 | Val Loss: 0.0178\n",
      "Epoch 76/500 | Train Loss: 0.0169 | Val Loss: 0.0177\n",
      "Epoch 77/500 | Train Loss: 0.0161 | Val Loss: 0.0176\n",
      "Epoch 78/500 | Train Loss: 0.0173 | Val Loss: 0.0176\n",
      "Epoch 79/500 | Train Loss: 0.0166 | Val Loss: 0.0175\n",
      "Epoch 80/500 | Train Loss: 0.0171 | Val Loss: 0.0173\n",
      "Epoch 81/500 | Train Loss: 0.0159 | Val Loss: 0.0175\n",
      "Epoch 82/500 | Train Loss: 0.0160 | Val Loss: 0.0174\n",
      "Epoch 83/500 | Train Loss: 0.0160 | Val Loss: 0.0173\n",
      "Epoch 84/500 | Train Loss: 0.0161 | Val Loss: 0.0173\n",
      "Epoch 85/500 | Train Loss: 0.0152 | Val Loss: 0.0172\n",
      "Epoch 86/500 | Train Loss: 0.0160 | Val Loss: 0.0171\n",
      "Epoch 87/500 | Train Loss: 0.0163 | Val Loss: 0.0171\n",
      "Epoch 88/500 | Train Loss: 0.0162 | Val Loss: 0.0171\n",
      "Epoch 89/500 | Train Loss: 0.0154 | Val Loss: 0.0171\n",
      "Epoch 90/500 | Train Loss: 0.0155 | Val Loss: 0.0171\n",
      "Epoch 91/500 | Train Loss: 0.0158 | Val Loss: 0.0170\n",
      "Epoch 92/500 | Train Loss: 0.0160 | Val Loss: 0.0168\n",
      "Epoch 93/500 | Train Loss: 0.0158 | Val Loss: 0.0169\n",
      "Epoch 94/500 | Train Loss: 0.0155 | Val Loss: 0.0169\n",
      "Epoch 95/500 | Train Loss: 0.0160 | Val Loss: 0.0168\n",
      "Epoch 96/500 | Train Loss: 0.0152 | Val Loss: 0.0167\n",
      "Epoch 97/500 | Train Loss: 0.0157 | Val Loss: 0.0168\n",
      "Epoch 98/500 | Train Loss: 0.0155 | Val Loss: 0.0167\n",
      "Epoch 99/500 | Train Loss: 0.0158 | Val Loss: 0.0166\n",
      "Epoch 100/500 | Train Loss: 0.0159 | Val Loss: 0.0166\n",
      "Epoch 101/500 | Train Loss: 0.0156 | Val Loss: 0.0166\n",
      "Epoch 102/500 | Train Loss: 0.0151 | Val Loss: 0.0166\n",
      "Epoch 103/500 | Train Loss: 0.0153 | Val Loss: 0.0165\n",
      "Epoch 104/500 | Train Loss: 0.0153 | Val Loss: 0.0165\n",
      "Epoch 105/500 | Train Loss: 0.0153 | Val Loss: 0.0165\n",
      "Epoch 106/500 | Train Loss: 0.0153 | Val Loss: 0.0165\n",
      "Epoch 107/500 | Train Loss: 0.0149 | Val Loss: 0.0165\n",
      "Epoch 108/500 | Train Loss: 0.0151 | Val Loss: 0.0164\n",
      "Epoch 109/500 | Train Loss: 0.0151 | Val Loss: 0.0164\n",
      "Epoch 110/500 | Train Loss: 0.0151 | Val Loss: 0.0164\n",
      "Epoch 111/500 | Train Loss: 0.0152 | Val Loss: 0.0163\n",
      "Epoch 112/500 | Train Loss: 0.0150 | Val Loss: 0.0162\n",
      "Epoch 113/500 | Train Loss: 0.0149 | Val Loss: 0.0161\n",
      "Epoch 114/500 | Train Loss: 0.0144 | Val Loss: 0.0161\n",
      "Epoch 115/500 | Train Loss: 0.0150 | Val Loss: 0.0162\n",
      "Epoch 116/500 | Train Loss: 0.0147 | Val Loss: 0.0161\n",
      "Epoch 117/500 | Train Loss: 0.0151 | Val Loss: 0.0160\n",
      "Epoch 118/500 | Train Loss: 0.0149 | Val Loss: 0.0161\n",
      "Epoch 119/500 | Train Loss: 0.0147 | Val Loss: 0.0162\n",
      "Epoch 120/500 | Train Loss: 0.0150 | Val Loss: 0.0161\n",
      "Epoch 121/500 | Train Loss: 0.0149 | Val Loss: 0.0161\n",
      "Epoch 122/500 | Train Loss: 0.0147 | Val Loss: 0.0161\n",
      "Epoch 123/500 | Train Loss: 0.0152 | Val Loss: 0.0161\n",
      "Epoch 124/500 | Train Loss: 0.0144 | Val Loss: 0.0161\n",
      "Epoch 125/500 | Train Loss: 0.0149 | Val Loss: 0.0160\n",
      "Epoch 126/500 | Train Loss: 0.0148 | Val Loss: 0.0161\n",
      "Epoch 127/500 | Train Loss: 0.0148 | Val Loss: 0.0160\n",
      "Epoch 128/500 | Train Loss: 0.0147 | Val Loss: 0.0160\n",
      "Epoch 129/500 | Train Loss: 0.0147 | Val Loss: 0.0160\n",
      "Epoch 130/500 | Train Loss: 0.0144 | Val Loss: 0.0159\n",
      "Epoch 131/500 | Train Loss: 0.0146 | Val Loss: 0.0159\n",
      "Epoch 132/500 | Train Loss: 0.0144 | Val Loss: 0.0158\n",
      "Epoch 133/500 | Train Loss: 0.0142 | Val Loss: 0.0158\n",
      "Epoch 134/500 | Train Loss: 0.0147 | Val Loss: 0.0158\n",
      "Epoch 135/500 | Train Loss: 0.0140 | Val Loss: 0.0158\n",
      "Epoch 136/500 | Train Loss: 0.0141 | Val Loss: 0.0157\n",
      "Epoch 137/500 | Train Loss: 0.0145 | Val Loss: 0.0157\n",
      "Epoch 138/500 | Train Loss: 0.0143 | Val Loss: 0.0156\n",
      "Epoch 139/500 | Train Loss: 0.0142 | Val Loss: 0.0155\n",
      "Epoch 140/500 | Train Loss: 0.0145 | Val Loss: 0.0156\n",
      "Epoch 141/500 | Train Loss: 0.0145 | Val Loss: 0.0156\n",
      "Epoch 142/500 | Train Loss: 0.0144 | Val Loss: 0.0155\n",
      "Epoch 143/500 | Train Loss: 0.0137 | Val Loss: 0.0155\n",
      "Epoch 144/500 | Train Loss: 0.0139 | Val Loss: 0.0155\n",
      "Epoch 145/500 | Train Loss: 0.0141 | Val Loss: 0.0154\n",
      "Epoch 146/500 | Train Loss: 0.0142 | Val Loss: 0.0154\n",
      "Epoch 147/500 | Train Loss: 0.0144 | Val Loss: 0.0154\n",
      "Epoch 148/500 | Train Loss: 0.0141 | Val Loss: 0.0154\n",
      "Epoch 149/500 | Train Loss: 0.0142 | Val Loss: 0.0154\n",
      "Epoch 150/500 | Train Loss: 0.0139 | Val Loss: 0.0153\n",
      "Epoch 151/500 | Train Loss: 0.0135 | Val Loss: 0.0152\n",
      "Epoch 152/500 | Train Loss: 0.0145 | Val Loss: 0.0153\n",
      "Epoch 153/500 | Train Loss: 0.0140 | Val Loss: 0.0154\n",
      "Epoch 154/500 | Train Loss: 0.0141 | Val Loss: 0.0153\n",
      "Epoch 155/500 | Train Loss: 0.0140 | Val Loss: 0.0153\n",
      "Epoch 156/500 | Train Loss: 0.0138 | Val Loss: 0.0152\n",
      "Epoch 157/500 | Train Loss: 0.0142 | Val Loss: 0.0153\n",
      "Epoch 158/500 | Train Loss: 0.0141 | Val Loss: 0.0152\n",
      "Epoch 159/500 | Train Loss: 0.0138 | Val Loss: 0.0152\n",
      "Epoch 160/500 | Train Loss: 0.0140 | Val Loss: 0.0153\n",
      "Epoch 161/500 | Train Loss: 0.0141 | Val Loss: 0.0152\n",
      "Epoch 162/500 | Train Loss: 0.0142 | Val Loss: 0.0154\n",
      "Epoch 163/500 | Train Loss: 0.0138 | Val Loss: 0.0153\n",
      "Epoch 164/500 | Train Loss: 0.0134 | Val Loss: 0.0152\n",
      "Epoch 165/500 | Train Loss: 0.0134 | Val Loss: 0.0152\n",
      "Epoch 166/500 | Train Loss: 0.0139 | Val Loss: 0.0152\n",
      "Epoch 167/500 | Train Loss: 0.0140 | Val Loss: 0.0151\n",
      "Epoch 168/500 | Train Loss: 0.0135 | Val Loss: 0.0151\n",
      "Epoch 169/500 | Train Loss: 0.0139 | Val Loss: 0.0151\n",
      "Epoch 170/500 | Train Loss: 0.0138 | Val Loss: 0.0151\n",
      "Epoch 171/500 | Train Loss: 0.0133 | Val Loss: 0.0150\n",
      "Epoch 172/500 | Train Loss: 0.0136 | Val Loss: 0.0151\n",
      "Epoch 173/500 | Train Loss: 0.0132 | Val Loss: 0.0150\n",
      "Epoch 174/500 | Train Loss: 0.0138 | Val Loss: 0.0150\n",
      "Epoch 175/500 | Train Loss: 0.0136 | Val Loss: 0.0150\n",
      "Epoch 176/500 | Train Loss: 0.0131 | Val Loss: 0.0150\n",
      "Epoch 177/500 | Train Loss: 0.0139 | Val Loss: 0.0150\n",
      "Epoch 178/500 | Train Loss: 0.0136 | Val Loss: 0.0149\n",
      "Epoch 179/500 | Train Loss: 0.0141 | Val Loss: 0.0149\n",
      "Epoch 180/500 | Train Loss: 0.0133 | Val Loss: 0.0149\n",
      "Epoch 181/500 | Train Loss: 0.0135 | Val Loss: 0.0149\n",
      "Epoch 182/500 | Train Loss: 0.0133 | Val Loss: 0.0147\n",
      "Epoch 183/500 | Train Loss: 0.0139 | Val Loss: 0.0148\n",
      "Epoch 184/500 | Train Loss: 0.0134 | Val Loss: 0.0149\n",
      "Epoch 185/500 | Train Loss: 0.0132 | Val Loss: 0.0149\n",
      "Epoch 186/500 | Train Loss: 0.0135 | Val Loss: 0.0148\n",
      "Epoch 187/500 | Train Loss: 0.0137 | Val Loss: 0.0149\n",
      "Epoch 188/500 | Train Loss: 0.0131 | Val Loss: 0.0148\n",
      "Epoch 189/500 | Train Loss: 0.0137 | Val Loss: 0.0149\n",
      "Epoch 190/500 | Train Loss: 0.0133 | Val Loss: 0.0147\n",
      "Epoch 191/500 | Train Loss: 0.0133 | Val Loss: 0.0148\n",
      "早停步 epoch= 192\n",
      "训练完成\n",
      "=== 网格搜索 patience=15 ===\n",
      "Epoch 1/500 | Train Loss: 0.1526 | Val Loss: 0.1291\n",
      "Epoch 2/500 | Train Loss: 0.1019 | Val Loss: 0.0760\n",
      "Epoch 3/500 | Train Loss: 0.0561 | Val Loss: 0.0513\n",
      "Epoch 4/500 | Train Loss: 0.0419 | Val Loss: 0.0482\n",
      "Epoch 5/500 | Train Loss: 0.0397 | Val Loss: 0.0453\n",
      "Epoch 6/500 | Train Loss: 0.0386 | Val Loss: 0.0418\n",
      "Epoch 7/500 | Train Loss: 0.0351 | Val Loss: 0.0383\n",
      "Epoch 8/500 | Train Loss: 0.0344 | Val Loss: 0.0349\n",
      "Epoch 9/500 | Train Loss: 0.0312 | Val Loss: 0.0329\n",
      "Epoch 10/500 | Train Loss: 0.0303 | Val Loss: 0.0303\n",
      "Epoch 11/500 | Train Loss: 0.0279 | Val Loss: 0.0284\n",
      "Epoch 12/500 | Train Loss: 0.0274 | Val Loss: 0.0270\n",
      "Epoch 13/500 | Train Loss: 0.0262 | Val Loss: 0.0258\n",
      "Epoch 14/500 | Train Loss: 0.0254 | Val Loss: 0.0249\n",
      "Epoch 15/500 | Train Loss: 0.0247 | Val Loss: 0.0239\n",
      "Epoch 16/500 | Train Loss: 0.0249 | Val Loss: 0.0234\n",
      "Epoch 17/500 | Train Loss: 0.0253 | Val Loss: 0.0232\n",
      "Epoch 18/500 | Train Loss: 0.0230 | Val Loss: 0.0227\n",
      "Epoch 19/500 | Train Loss: 0.0232 | Val Loss: 0.0222\n",
      "Epoch 20/500 | Train Loss: 0.0228 | Val Loss: 0.0220\n",
      "Epoch 21/500 | Train Loss: 0.0226 | Val Loss: 0.0220\n",
      "Epoch 22/500 | Train Loss: 0.0221 | Val Loss: 0.0216\n",
      "Epoch 23/500 | Train Loss: 0.0231 | Val Loss: 0.0214\n",
      "Epoch 24/500 | Train Loss: 0.0223 | Val Loss: 0.0214\n",
      "Epoch 25/500 | Train Loss: 0.0215 | Val Loss: 0.0212\n",
      "Epoch 26/500 | Train Loss: 0.0216 | Val Loss: 0.0212\n",
      "Epoch 27/500 | Train Loss: 0.0208 | Val Loss: 0.0209\n",
      "Epoch 28/500 | Train Loss: 0.0217 | Val Loss: 0.0209\n",
      "Epoch 29/500 | Train Loss: 0.0210 | Val Loss: 0.0209\n",
      "Epoch 30/500 | Train Loss: 0.0206 | Val Loss: 0.0207\n",
      "Epoch 31/500 | Train Loss: 0.0209 | Val Loss: 0.0205\n",
      "Epoch 32/500 | Train Loss: 0.0208 | Val Loss: 0.0206\n",
      "Epoch 33/500 | Train Loss: 0.0206 | Val Loss: 0.0205\n",
      "Epoch 34/500 | Train Loss: 0.0202 | Val Loss: 0.0204\n",
      "Epoch 35/500 | Train Loss: 0.0212 | Val Loss: 0.0204\n",
      "Epoch 36/500 | Train Loss: 0.0195 | Val Loss: 0.0202\n",
      "Epoch 37/500 | Train Loss: 0.0197 | Val Loss: 0.0201\n",
      "Epoch 38/500 | Train Loss: 0.0197 | Val Loss: 0.0201\n",
      "Epoch 39/500 | Train Loss: 0.0194 | Val Loss: 0.0201\n",
      "Epoch 40/500 | Train Loss: 0.0192 | Val Loss: 0.0200\n",
      "Epoch 41/500 | Train Loss: 0.0196 | Val Loss: 0.0199\n",
      "Epoch 42/500 | Train Loss: 0.0195 | Val Loss: 0.0199\n",
      "Epoch 43/500 | Train Loss: 0.0199 | Val Loss: 0.0199\n",
      "Epoch 44/500 | Train Loss: 0.0197 | Val Loss: 0.0198\n",
      "Epoch 45/500 | Train Loss: 0.0198 | Val Loss: 0.0199\n",
      "Epoch 46/500 | Train Loss: 0.0188 | Val Loss: 0.0198\n",
      "Epoch 47/500 | Train Loss: 0.0189 | Val Loss: 0.0196\n",
      "Epoch 48/500 | Train Loss: 0.0188 | Val Loss: 0.0196\n",
      "Epoch 49/500 | Train Loss: 0.0192 | Val Loss: 0.0195\n",
      "Epoch 50/500 | Train Loss: 0.0185 | Val Loss: 0.0195\n",
      "Epoch 51/500 | Train Loss: 0.0183 | Val Loss: 0.0194\n",
      "Epoch 52/500 | Train Loss: 0.0187 | Val Loss: 0.0194\n",
      "Epoch 53/500 | Train Loss: 0.0185 | Val Loss: 0.0192\n",
      "Epoch 54/500 | Train Loss: 0.0187 | Val Loss: 0.0193\n",
      "Epoch 55/500 | Train Loss: 0.0184 | Val Loss: 0.0190\n",
      "Epoch 56/500 | Train Loss: 0.0182 | Val Loss: 0.0190\n",
      "Epoch 57/500 | Train Loss: 0.0178 | Val Loss: 0.0189\n",
      "Epoch 58/500 | Train Loss: 0.0180 | Val Loss: 0.0188\n",
      "Epoch 59/500 | Train Loss: 0.0174 | Val Loss: 0.0188\n",
      "Epoch 60/500 | Train Loss: 0.0186 | Val Loss: 0.0188\n",
      "Epoch 61/500 | Train Loss: 0.0175 | Val Loss: 0.0185\n",
      "Epoch 62/500 | Train Loss: 0.0172 | Val Loss: 0.0185\n",
      "Epoch 63/500 | Train Loss: 0.0174 | Val Loss: 0.0185\n",
      "Epoch 64/500 | Train Loss: 0.0177 | Val Loss: 0.0184\n",
      "Epoch 65/500 | Train Loss: 0.0179 | Val Loss: 0.0183\n",
      "Epoch 66/500 | Train Loss: 0.0180 | Val Loss: 0.0184\n",
      "Epoch 67/500 | Train Loss: 0.0171 | Val Loss: 0.0182\n",
      "Epoch 68/500 | Train Loss: 0.0175 | Val Loss: 0.0181\n",
      "Epoch 69/500 | Train Loss: 0.0175 | Val Loss: 0.0181\n",
      "Epoch 70/500 | Train Loss: 0.0173 | Val Loss: 0.0181\n",
      "Epoch 71/500 | Train Loss: 0.0168 | Val Loss: 0.0179\n",
      "Epoch 72/500 | Train Loss: 0.0169 | Val Loss: 0.0179\n",
      "Epoch 73/500 | Train Loss: 0.0164 | Val Loss: 0.0178\n",
      "Epoch 74/500 | Train Loss: 0.0165 | Val Loss: 0.0177\n",
      "Epoch 75/500 | Train Loss: 0.0166 | Val Loss: 0.0177\n",
      "Epoch 76/500 | Train Loss: 0.0167 | Val Loss: 0.0175\n",
      "Epoch 77/500 | Train Loss: 0.0164 | Val Loss: 0.0175\n",
      "Epoch 78/500 | Train Loss: 0.0157 | Val Loss: 0.0174\n",
      "Epoch 79/500 | Train Loss: 0.0167 | Val Loss: 0.0174\n",
      "Epoch 80/500 | Train Loss: 0.0164 | Val Loss: 0.0173\n",
      "Epoch 81/500 | Train Loss: 0.0166 | Val Loss: 0.0172\n",
      "Epoch 82/500 | Train Loss: 0.0163 | Val Loss: 0.0173\n",
      "Epoch 83/500 | Train Loss: 0.0167 | Val Loss: 0.0173\n",
      "Epoch 84/500 | Train Loss: 0.0164 | Val Loss: 0.0173\n",
      "Epoch 85/500 | Train Loss: 0.0163 | Val Loss: 0.0171\n",
      "Epoch 86/500 | Train Loss: 0.0159 | Val Loss: 0.0170\n",
      "Epoch 87/500 | Train Loss: 0.0164 | Val Loss: 0.0170\n",
      "Epoch 88/500 | Train Loss: 0.0163 | Val Loss: 0.0169\n",
      "Epoch 89/500 | Train Loss: 0.0160 | Val Loss: 0.0169\n",
      "Epoch 90/500 | Train Loss: 0.0159 | Val Loss: 0.0168\n",
      "Epoch 91/500 | Train Loss: 0.0162 | Val Loss: 0.0169\n",
      "Epoch 92/500 | Train Loss: 0.0156 | Val Loss: 0.0169\n",
      "Epoch 93/500 | Train Loss: 0.0156 | Val Loss: 0.0168\n",
      "Epoch 94/500 | Train Loss: 0.0157 | Val Loss: 0.0167\n",
      "Epoch 95/500 | Train Loss: 0.0156 | Val Loss: 0.0166\n",
      "Epoch 96/500 | Train Loss: 0.0153 | Val Loss: 0.0167\n",
      "Epoch 97/500 | Train Loss: 0.0153 | Val Loss: 0.0166\n",
      "Epoch 98/500 | Train Loss: 0.0153 | Val Loss: 0.0165\n",
      "Epoch 99/500 | Train Loss: 0.0153 | Val Loss: 0.0165\n",
      "Epoch 100/500 | Train Loss: 0.0156 | Val Loss: 0.0164\n",
      "Epoch 101/500 | Train Loss: 0.0154 | Val Loss: 0.0164\n",
      "Epoch 102/500 | Train Loss: 0.0154 | Val Loss: 0.0164\n",
      "Epoch 103/500 | Train Loss: 0.0152 | Val Loss: 0.0163\n",
      "Epoch 104/500 | Train Loss: 0.0159 | Val Loss: 0.0163\n",
      "Epoch 105/500 | Train Loss: 0.0157 | Val Loss: 0.0163\n",
      "Epoch 106/500 | Train Loss: 0.0152 | Val Loss: 0.0163\n",
      "Epoch 107/500 | Train Loss: 0.0150 | Val Loss: 0.0164\n",
      "Epoch 108/500 | Train Loss: 0.0151 | Val Loss: 0.0163\n",
      "Epoch 109/500 | Train Loss: 0.0155 | Val Loss: 0.0163\n",
      "Epoch 110/500 | Train Loss: 0.0146 | Val Loss: 0.0162\n",
      "Epoch 111/500 | Train Loss: 0.0149 | Val Loss: 0.0162\n",
      "Epoch 112/500 | Train Loss: 0.0145 | Val Loss: 0.0162\n",
      "Epoch 113/500 | Train Loss: 0.0152 | Val Loss: 0.0161\n",
      "Epoch 114/500 | Train Loss: 0.0151 | Val Loss: 0.0161\n",
      "Epoch 115/500 | Train Loss: 0.0148 | Val Loss: 0.0160\n",
      "Epoch 116/500 | Train Loss: 0.0148 | Val Loss: 0.0160\n",
      "Epoch 117/500 | Train Loss: 0.0145 | Val Loss: 0.0159\n",
      "Epoch 118/500 | Train Loss: 0.0150 | Val Loss: 0.0161\n",
      "Epoch 119/500 | Train Loss: 0.0146 | Val Loss: 0.0159\n",
      "Epoch 120/500 | Train Loss: 0.0144 | Val Loss: 0.0160\n",
      "Epoch 121/500 | Train Loss: 0.0148 | Val Loss: 0.0160\n",
      "Epoch 122/500 | Train Loss: 0.0152 | Val Loss: 0.0160\n",
      "Epoch 123/500 | Train Loss: 0.0147 | Val Loss: 0.0160\n",
      "Epoch 124/500 | Train Loss: 0.0146 | Val Loss: 0.0160\n",
      "Epoch 125/500 | Train Loss: 0.0143 | Val Loss: 0.0158\n",
      "Epoch 126/500 | Train Loss: 0.0152 | Val Loss: 0.0158\n",
      "Epoch 127/500 | Train Loss: 0.0149 | Val Loss: 0.0158\n",
      "Epoch 128/500 | Train Loss: 0.0141 | Val Loss: 0.0158\n",
      "Epoch 129/500 | Train Loss: 0.0145 | Val Loss: 0.0157\n",
      "Epoch 130/500 | Train Loss: 0.0141 | Val Loss: 0.0158\n",
      "Epoch 131/500 | Train Loss: 0.0143 | Val Loss: 0.0157\n",
      "Epoch 132/500 | Train Loss: 0.0145 | Val Loss: 0.0156\n",
      "Epoch 133/500 | Train Loss: 0.0144 | Val Loss: 0.0156\n",
      "Epoch 134/500 | Train Loss: 0.0146 | Val Loss: 0.0155\n",
      "Epoch 135/500 | Train Loss: 0.0141 | Val Loss: 0.0154\n",
      "Epoch 136/500 | Train Loss: 0.0143 | Val Loss: 0.0154\n",
      "Epoch 137/500 | Train Loss: 0.0143 | Val Loss: 0.0156\n",
      "Epoch 138/500 | Train Loss: 0.0142 | Val Loss: 0.0156\n",
      "Epoch 139/500 | Train Loss: 0.0143 | Val Loss: 0.0156\n",
      "Epoch 140/500 | Train Loss: 0.0136 | Val Loss: 0.0155\n",
      "Epoch 141/500 | Train Loss: 0.0144 | Val Loss: 0.0152\n",
      "Epoch 142/500 | Train Loss: 0.0139 | Val Loss: 0.0150\n",
      "Epoch 143/500 | Train Loss: 0.0146 | Val Loss: 0.0153\n",
      "Epoch 144/500 | Train Loss: 0.0136 | Val Loss: 0.0154\n",
      "Epoch 145/500 | Train Loss: 0.0141 | Val Loss: 0.0154\n",
      "Epoch 146/500 | Train Loss: 0.0144 | Val Loss: 0.0156\n",
      "Epoch 147/500 | Train Loss: 0.0141 | Val Loss: 0.0155\n",
      "Epoch 148/500 | Train Loss: 0.0140 | Val Loss: 0.0155\n",
      "Epoch 149/500 | Train Loss: 0.0138 | Val Loss: 0.0153\n",
      "Epoch 150/500 | Train Loss: 0.0130 | Val Loss: 0.0152\n",
      "Epoch 151/500 | Train Loss: 0.0138 | Val Loss: 0.0154\n",
      "Epoch 152/500 | Train Loss: 0.0133 | Val Loss: 0.0153\n",
      "Epoch 153/500 | Train Loss: 0.0146 | Val Loss: 0.0154\n",
      "Epoch 154/500 | Train Loss: 0.0141 | Val Loss: 0.0154\n",
      "Epoch 155/500 | Train Loss: 0.0138 | Val Loss: 0.0153\n",
      "Epoch 156/500 | Train Loss: 0.0136 | Val Loss: 0.0151\n",
      "早停步 epoch= 157\n",
      "训练完成\n",
      "=== 网格搜索 patience=20 ===\n",
      "Epoch 1/500 | Train Loss: 0.1524 | Val Loss: 0.1294\n",
      "Epoch 2/500 | Train Loss: 0.1023 | Val Loss: 0.0764\n",
      "Epoch 3/500 | Train Loss: 0.0574 | Val Loss: 0.0511\n",
      "Epoch 4/500 | Train Loss: 0.0421 | Val Loss: 0.0479\n",
      "Epoch 5/500 | Train Loss: 0.0387 | Val Loss: 0.0451\n",
      "Epoch 6/500 | Train Loss: 0.0373 | Val Loss: 0.0421\n",
      "Epoch 7/500 | Train Loss: 0.0356 | Val Loss: 0.0383\n",
      "Epoch 8/500 | Train Loss: 0.0334 | Val Loss: 0.0354\n",
      "Epoch 9/500 | Train Loss: 0.0319 | Val Loss: 0.0329\n",
      "Epoch 10/500 | Train Loss: 0.0298 | Val Loss: 0.0300\n",
      "Epoch 11/500 | Train Loss: 0.0292 | Val Loss: 0.0279\n",
      "Epoch 12/500 | Train Loss: 0.0277 | Val Loss: 0.0264\n",
      "Epoch 13/500 | Train Loss: 0.0267 | Val Loss: 0.0253\n",
      "Epoch 14/500 | Train Loss: 0.0255 | Val Loss: 0.0245\n",
      "Epoch 15/500 | Train Loss: 0.0252 | Val Loss: 0.0238\n",
      "Epoch 16/500 | Train Loss: 0.0249 | Val Loss: 0.0233\n",
      "Epoch 17/500 | Train Loss: 0.0246 | Val Loss: 0.0231\n",
      "Epoch 18/500 | Train Loss: 0.0241 | Val Loss: 0.0228\n",
      "Epoch 19/500 | Train Loss: 0.0229 | Val Loss: 0.0223\n",
      "Epoch 20/500 | Train Loss: 0.0231 | Val Loss: 0.0220\n",
      "Epoch 21/500 | Train Loss: 0.0234 | Val Loss: 0.0219\n",
      "Epoch 22/500 | Train Loss: 0.0230 | Val Loss: 0.0219\n",
      "Epoch 23/500 | Train Loss: 0.0217 | Val Loss: 0.0215\n",
      "Epoch 24/500 | Train Loss: 0.0215 | Val Loss: 0.0211\n",
      "Epoch 25/500 | Train Loss: 0.0216 | Val Loss: 0.0210\n",
      "Epoch 26/500 | Train Loss: 0.0209 | Val Loss: 0.0209\n",
      "Epoch 27/500 | Train Loss: 0.0215 | Val Loss: 0.0209\n",
      "Epoch 28/500 | Train Loss: 0.0217 | Val Loss: 0.0210\n",
      "Epoch 29/500 | Train Loss: 0.0201 | Val Loss: 0.0207\n",
      "Epoch 30/500 | Train Loss: 0.0200 | Val Loss: 0.0206\n",
      "Epoch 31/500 | Train Loss: 0.0206 | Val Loss: 0.0204\n",
      "Epoch 32/500 | Train Loss: 0.0202 | Val Loss: 0.0204\n",
      "Epoch 33/500 | Train Loss: 0.0202 | Val Loss: 0.0203\n",
      "Epoch 34/500 | Train Loss: 0.0206 | Val Loss: 0.0202\n",
      "Epoch 35/500 | Train Loss: 0.0198 | Val Loss: 0.0200\n",
      "Epoch 36/500 | Train Loss: 0.0200 | Val Loss: 0.0200\n",
      "Epoch 37/500 | Train Loss: 0.0205 | Val Loss: 0.0200\n",
      "Epoch 38/500 | Train Loss: 0.0203 | Val Loss: 0.0201\n",
      "Epoch 39/500 | Train Loss: 0.0201 | Val Loss: 0.0201\n",
      "Epoch 40/500 | Train Loss: 0.0197 | Val Loss: 0.0199\n",
      "Epoch 41/500 | Train Loss: 0.0198 | Val Loss: 0.0198\n",
      "Epoch 42/500 | Train Loss: 0.0196 | Val Loss: 0.0196\n",
      "Epoch 43/500 | Train Loss: 0.0196 | Val Loss: 0.0196\n",
      "Epoch 44/500 | Train Loss: 0.0191 | Val Loss: 0.0197\n",
      "Epoch 45/500 | Train Loss: 0.0192 | Val Loss: 0.0197\n",
      "Epoch 46/500 | Train Loss: 0.0192 | Val Loss: 0.0193\n",
      "Epoch 47/500 | Train Loss: 0.0189 | Val Loss: 0.0191\n",
      "Epoch 48/500 | Train Loss: 0.0187 | Val Loss: 0.0194\n",
      "Epoch 49/500 | Train Loss: 0.0186 | Val Loss: 0.0193\n",
      "Epoch 50/500 | Train Loss: 0.0185 | Val Loss: 0.0189\n",
      "Epoch 51/500 | Train Loss: 0.0193 | Val Loss: 0.0192\n",
      "Epoch 52/500 | Train Loss: 0.0188 | Val Loss: 0.0193\n",
      "Epoch 53/500 | Train Loss: 0.0186 | Val Loss: 0.0191\n",
      "Epoch 54/500 | Train Loss: 0.0184 | Val Loss: 0.0190\n",
      "Epoch 55/500 | Train Loss: 0.0186 | Val Loss: 0.0188\n",
      "Epoch 56/500 | Train Loss: 0.0184 | Val Loss: 0.0187\n",
      "Epoch 57/500 | Train Loss: 0.0177 | Val Loss: 0.0188\n",
      "Epoch 58/500 | Train Loss: 0.0174 | Val Loss: 0.0188\n",
      "Epoch 59/500 | Train Loss: 0.0181 | Val Loss: 0.0188\n",
      "Epoch 60/500 | Train Loss: 0.0177 | Val Loss: 0.0188\n",
      "Epoch 61/500 | Train Loss: 0.0173 | Val Loss: 0.0185\n",
      "Epoch 62/500 | Train Loss: 0.0175 | Val Loss: 0.0184\n",
      "Epoch 63/500 | Train Loss: 0.0172 | Val Loss: 0.0184\n",
      "Epoch 64/500 | Train Loss: 0.0173 | Val Loss: 0.0183\n",
      "Epoch 65/500 | Train Loss: 0.0179 | Val Loss: 0.0184\n",
      "Epoch 66/500 | Train Loss: 0.0178 | Val Loss: 0.0182\n",
      "Epoch 67/500 | Train Loss: 0.0167 | Val Loss: 0.0181\n",
      "Epoch 68/500 | Train Loss: 0.0167 | Val Loss: 0.0181\n",
      "Epoch 69/500 | Train Loss: 0.0169 | Val Loss: 0.0180\n",
      "Epoch 70/500 | Train Loss: 0.0170 | Val Loss: 0.0180\n",
      "Epoch 71/500 | Train Loss: 0.0167 | Val Loss: 0.0179\n",
      "Epoch 72/500 | Train Loss: 0.0179 | Val Loss: 0.0179\n",
      "Epoch 73/500 | Train Loss: 0.0167 | Val Loss: 0.0178\n",
      "Epoch 74/500 | Train Loss: 0.0162 | Val Loss: 0.0178\n",
      "Epoch 75/500 | Train Loss: 0.0175 | Val Loss: 0.0178\n",
      "Epoch 76/500 | Train Loss: 0.0164 | Val Loss: 0.0175\n",
      "Epoch 77/500 | Train Loss: 0.0164 | Val Loss: 0.0176\n",
      "Epoch 78/500 | Train Loss: 0.0163 | Val Loss: 0.0177\n",
      "Epoch 79/500 | Train Loss: 0.0158 | Val Loss: 0.0175\n",
      "Epoch 80/500 | Train Loss: 0.0164 | Val Loss: 0.0175\n",
      "Epoch 81/500 | Train Loss: 0.0168 | Val Loss: 0.0175\n",
      "Epoch 82/500 | Train Loss: 0.0163 | Val Loss: 0.0174\n",
      "Epoch 83/500 | Train Loss: 0.0165 | Val Loss: 0.0173\n",
      "Epoch 84/500 | Train Loss: 0.0165 | Val Loss: 0.0173\n",
      "Epoch 85/500 | Train Loss: 0.0163 | Val Loss: 0.0173\n",
      "Epoch 86/500 | Train Loss: 0.0159 | Val Loss: 0.0173\n",
      "Epoch 87/500 | Train Loss: 0.0160 | Val Loss: 0.0173\n",
      "Epoch 88/500 | Train Loss: 0.0155 | Val Loss: 0.0172\n",
      "Epoch 89/500 | Train Loss: 0.0164 | Val Loss: 0.0172\n",
      "Epoch 90/500 | Train Loss: 0.0161 | Val Loss: 0.0172\n",
      "Epoch 91/500 | Train Loss: 0.0164 | Val Loss: 0.0173\n",
      "Epoch 92/500 | Train Loss: 0.0161 | Val Loss: 0.0171\n",
      "Epoch 93/500 | Train Loss: 0.0160 | Val Loss: 0.0170\n",
      "Epoch 94/500 | Train Loss: 0.0160 | Val Loss: 0.0171\n",
      "Epoch 95/500 | Train Loss: 0.0155 | Val Loss: 0.0170\n",
      "Epoch 96/500 | Train Loss: 0.0159 | Val Loss: 0.0169\n",
      "Epoch 97/500 | Train Loss: 0.0157 | Val Loss: 0.0170\n",
      "Epoch 98/500 | Train Loss: 0.0158 | Val Loss: 0.0170\n",
      "Epoch 99/500 | Train Loss: 0.0160 | Val Loss: 0.0170\n",
      "Epoch 100/500 | Train Loss: 0.0151 | Val Loss: 0.0168\n",
      "Epoch 101/500 | Train Loss: 0.0155 | Val Loss: 0.0167\n",
      "Epoch 102/500 | Train Loss: 0.0148 | Val Loss: 0.0167\n",
      "Epoch 103/500 | Train Loss: 0.0154 | Val Loss: 0.0165\n",
      "Epoch 104/500 | Train Loss: 0.0153 | Val Loss: 0.0164\n",
      "Epoch 105/500 | Train Loss: 0.0151 | Val Loss: 0.0164\n",
      "Epoch 106/500 | Train Loss: 0.0155 | Val Loss: 0.0165\n",
      "Epoch 107/500 | Train Loss: 0.0156 | Val Loss: 0.0166\n",
      "Epoch 108/500 | Train Loss: 0.0156 | Val Loss: 0.0167\n",
      "Epoch 109/500 | Train Loss: 0.0149 | Val Loss: 0.0166\n",
      "Epoch 110/500 | Train Loss: 0.0148 | Val Loss: 0.0165\n",
      "Epoch 111/500 | Train Loss: 0.0148 | Val Loss: 0.0164\n",
      "Epoch 112/500 | Train Loss: 0.0156 | Val Loss: 0.0165\n",
      "Epoch 113/500 | Train Loss: 0.0150 | Val Loss: 0.0164\n",
      "Epoch 114/500 | Train Loss: 0.0152 | Val Loss: 0.0166\n",
      "Epoch 115/500 | Train Loss: 0.0152 | Val Loss: 0.0165\n",
      "Epoch 116/500 | Train Loss: 0.0148 | Val Loss: 0.0164\n",
      "Epoch 117/500 | Train Loss: 0.0149 | Val Loss: 0.0163\n",
      "Epoch 118/500 | Train Loss: 0.0151 | Val Loss: 0.0163\n",
      "Epoch 119/500 | Train Loss: 0.0150 | Val Loss: 0.0163\n",
      "Epoch 120/500 | Train Loss: 0.0144 | Val Loss: 0.0164\n",
      "Epoch 121/500 | Train Loss: 0.0150 | Val Loss: 0.0162\n",
      "Epoch 122/500 | Train Loss: 0.0150 | Val Loss: 0.0162\n",
      "Epoch 123/500 | Train Loss: 0.0149 | Val Loss: 0.0162\n",
      "Epoch 124/500 | Train Loss: 0.0147 | Val Loss: 0.0161\n",
      "Epoch 125/500 | Train Loss: 0.0139 | Val Loss: 0.0158\n",
      "Epoch 126/500 | Train Loss: 0.0146 | Val Loss: 0.0158\n",
      "Epoch 127/500 | Train Loss: 0.0145 | Val Loss: 0.0160\n",
      "Epoch 128/500 | Train Loss: 0.0149 | Val Loss: 0.0161\n",
      "Epoch 129/500 | Train Loss: 0.0144 | Val Loss: 0.0160\n",
      "Epoch 130/500 | Train Loss: 0.0147 | Val Loss: 0.0154\n",
      "Epoch 131/500 | Train Loss: 0.0145 | Val Loss: 0.0160\n",
      "Epoch 132/500 | Train Loss: 0.0141 | Val Loss: 0.0158\n",
      "Epoch 133/500 | Train Loss: 0.0144 | Val Loss: 0.0157\n",
      "Epoch 134/500 | Train Loss: 0.0143 | Val Loss: 0.0160\n",
      "Epoch 135/500 | Train Loss: 0.0148 | Val Loss: 0.0159\n",
      "Epoch 136/500 | Train Loss: 0.0150 | Val Loss: 0.0158\n",
      "Epoch 137/500 | Train Loss: 0.0144 | Val Loss: 0.0159\n",
      "Epoch 138/500 | Train Loss: 0.0151 | Val Loss: 0.0159\n",
      "Epoch 139/500 | Train Loss: 0.0141 | Val Loss: 0.0159\n",
      "Epoch 140/500 | Train Loss: 0.0142 | Val Loss: 0.0159\n",
      "Epoch 141/500 | Train Loss: 0.0142 | Val Loss: 0.0160\n",
      "Epoch 142/500 | Train Loss: 0.0135 | Val Loss: 0.0156\n",
      "Epoch 143/500 | Train Loss: 0.0142 | Val Loss: 0.0158\n",
      "Epoch 144/500 | Train Loss: 0.0147 | Val Loss: 0.0157\n",
      "Epoch 145/500 | Train Loss: 0.0141 | Val Loss: 0.0158\n",
      "Epoch 146/500 | Train Loss: 0.0144 | Val Loss: 0.0157\n",
      "Epoch 147/500 | Train Loss: 0.0144 | Val Loss: 0.0157\n",
      "Epoch 148/500 | Train Loss: 0.0139 | Val Loss: 0.0157\n",
      "Epoch 149/500 | Train Loss: 0.0139 | Val Loss: 0.0157\n",
      "早停步 epoch= 150\n",
      "训练完成\n",
      "=== 网格搜索 patience=25 ===\n",
      "Epoch 1/500 | Train Loss: 0.1526 | Val Loss: 0.1294\n",
      "Epoch 2/500 | Train Loss: 0.1034 | Val Loss: 0.0763\n",
      "Epoch 3/500 | Train Loss: 0.0590 | Val Loss: 0.0511\n",
      "Epoch 4/500 | Train Loss: 0.0425 | Val Loss: 0.0474\n",
      "Epoch 5/500 | Train Loss: 0.0401 | Val Loss: 0.0447\n",
      "Epoch 6/500 | Train Loss: 0.0381 | Val Loss: 0.0412\n",
      "Epoch 7/500 | Train Loss: 0.0349 | Val Loss: 0.0373\n",
      "Epoch 8/500 | Train Loss: 0.0338 | Val Loss: 0.0339\n",
      "Epoch 9/500 | Train Loss: 0.0307 | Val Loss: 0.0312\n",
      "Epoch 10/500 | Train Loss: 0.0296 | Val Loss: 0.0285\n",
      "Epoch 11/500 | Train Loss: 0.0271 | Val Loss: 0.0270\n",
      "Epoch 12/500 | Train Loss: 0.0272 | Val Loss: 0.0253\n",
      "Epoch 13/500 | Train Loss: 0.0257 | Val Loss: 0.0243\n",
      "Epoch 14/500 | Train Loss: 0.0254 | Val Loss: 0.0236\n",
      "Epoch 15/500 | Train Loss: 0.0237 | Val Loss: 0.0231\n",
      "Epoch 16/500 | Train Loss: 0.0243 | Val Loss: 0.0228\n",
      "Epoch 17/500 | Train Loss: 0.0239 | Val Loss: 0.0224\n",
      "Epoch 18/500 | Train Loss: 0.0233 | Val Loss: 0.0222\n",
      "Epoch 19/500 | Train Loss: 0.0233 | Val Loss: 0.0220\n",
      "Epoch 20/500 | Train Loss: 0.0227 | Val Loss: 0.0217\n",
      "Epoch 21/500 | Train Loss: 0.0219 | Val Loss: 0.0217\n",
      "Epoch 22/500 | Train Loss: 0.0228 | Val Loss: 0.0215\n",
      "Epoch 23/500 | Train Loss: 0.0221 | Val Loss: 0.0216\n",
      "Epoch 24/500 | Train Loss: 0.0215 | Val Loss: 0.0213\n",
      "Epoch 25/500 | Train Loss: 0.0212 | Val Loss: 0.0209\n",
      "Epoch 26/500 | Train Loss: 0.0214 | Val Loss: 0.0208\n",
      "Epoch 27/500 | Train Loss: 0.0217 | Val Loss: 0.0209\n",
      "Epoch 28/500 | Train Loss: 0.0210 | Val Loss: 0.0208\n",
      "Epoch 29/500 | Train Loss: 0.0222 | Val Loss: 0.0206\n",
      "Epoch 30/500 | Train Loss: 0.0217 | Val Loss: 0.0208\n",
      "Epoch 31/500 | Train Loss: 0.0212 | Val Loss: 0.0207\n",
      "Epoch 32/500 | Train Loss: 0.0203 | Val Loss: 0.0206\n",
      "Epoch 33/500 | Train Loss: 0.0207 | Val Loss: 0.0204\n",
      "Epoch 34/500 | Train Loss: 0.0201 | Val Loss: 0.0205\n",
      "Epoch 35/500 | Train Loss: 0.0200 | Val Loss: 0.0205\n",
      "Epoch 36/500 | Train Loss: 0.0194 | Val Loss: 0.0203\n",
      "Epoch 37/500 | Train Loss: 0.0204 | Val Loss: 0.0200\n",
      "Epoch 38/500 | Train Loss: 0.0203 | Val Loss: 0.0201\n",
      "Epoch 39/500 | Train Loss: 0.0203 | Val Loss: 0.0201\n",
      "Epoch 40/500 | Train Loss: 0.0196 | Val Loss: 0.0201\n",
      "Epoch 41/500 | Train Loss: 0.0189 | Val Loss: 0.0200\n",
      "Epoch 42/500 | Train Loss: 0.0197 | Val Loss: 0.0198\n",
      "Epoch 43/500 | Train Loss: 0.0187 | Val Loss: 0.0198\n",
      "Epoch 44/500 | Train Loss: 0.0190 | Val Loss: 0.0196\n",
      "Epoch 45/500 | Train Loss: 0.0190 | Val Loss: 0.0195\n",
      "Epoch 46/500 | Train Loss: 0.0184 | Val Loss: 0.0193\n",
      "Epoch 47/500 | Train Loss: 0.0188 | Val Loss: 0.0193\n",
      "Epoch 48/500 | Train Loss: 0.0187 | Val Loss: 0.0194\n",
      "Epoch 49/500 | Train Loss: 0.0192 | Val Loss: 0.0193\n",
      "Epoch 50/500 | Train Loss: 0.0188 | Val Loss: 0.0191\n",
      "Epoch 51/500 | Train Loss: 0.0184 | Val Loss: 0.0191\n",
      "Epoch 52/500 | Train Loss: 0.0181 | Val Loss: 0.0190\n",
      "Epoch 53/500 | Train Loss: 0.0185 | Val Loss: 0.0190\n",
      "Epoch 54/500 | Train Loss: 0.0186 | Val Loss: 0.0187\n",
      "Epoch 55/500 | Train Loss: 0.0185 | Val Loss: 0.0188\n",
      "Epoch 56/500 | Train Loss: 0.0176 | Val Loss: 0.0187\n",
      "Epoch 57/500 | Train Loss: 0.0181 | Val Loss: 0.0186\n",
      "Epoch 58/500 | Train Loss: 0.0179 | Val Loss: 0.0185\n",
      "Epoch 59/500 | Train Loss: 0.0177 | Val Loss: 0.0184\n",
      "Epoch 60/500 | Train Loss: 0.0172 | Val Loss: 0.0183\n",
      "Epoch 61/500 | Train Loss: 0.0181 | Val Loss: 0.0182\n",
      "Epoch 62/500 | Train Loss: 0.0175 | Val Loss: 0.0183\n",
      "Epoch 63/500 | Train Loss: 0.0174 | Val Loss: 0.0182\n",
      "Epoch 64/500 | Train Loss: 0.0171 | Val Loss: 0.0179\n",
      "Epoch 65/500 | Train Loss: 0.0178 | Val Loss: 0.0180\n",
      "Epoch 66/500 | Train Loss: 0.0173 | Val Loss: 0.0180\n",
      "Epoch 67/500 | Train Loss: 0.0173 | Val Loss: 0.0179\n",
      "Epoch 68/500 | Train Loss: 0.0169 | Val Loss: 0.0178\n",
      "Epoch 69/500 | Train Loss: 0.0167 | Val Loss: 0.0178\n",
      "Epoch 70/500 | Train Loss: 0.0166 | Val Loss: 0.0177\n",
      "Epoch 71/500 | Train Loss: 0.0174 | Val Loss: 0.0178\n",
      "Epoch 72/500 | Train Loss: 0.0170 | Val Loss: 0.0176\n",
      "Epoch 73/500 | Train Loss: 0.0168 | Val Loss: 0.0176\n",
      "Epoch 74/500 | Train Loss: 0.0171 | Val Loss: 0.0175\n",
      "Epoch 75/500 | Train Loss: 0.0162 | Val Loss: 0.0175\n",
      "Epoch 76/500 | Train Loss: 0.0159 | Val Loss: 0.0175\n",
      "Epoch 77/500 | Train Loss: 0.0169 | Val Loss: 0.0173\n",
      "Epoch 78/500 | Train Loss: 0.0165 | Val Loss: 0.0173\n",
      "Epoch 79/500 | Train Loss: 0.0165 | Val Loss: 0.0172\n",
      "Epoch 80/500 | Train Loss: 0.0160 | Val Loss: 0.0173\n",
      "Epoch 81/500 | Train Loss: 0.0159 | Val Loss: 0.0173\n",
      "Epoch 82/500 | Train Loss: 0.0161 | Val Loss: 0.0172\n",
      "Epoch 83/500 | Train Loss: 0.0157 | Val Loss: 0.0172\n",
      "Epoch 84/500 | Train Loss: 0.0160 | Val Loss: 0.0171\n",
      "Epoch 85/500 | Train Loss: 0.0157 | Val Loss: 0.0171\n",
      "Epoch 86/500 | Train Loss: 0.0158 | Val Loss: 0.0170\n",
      "Epoch 87/500 | Train Loss: 0.0165 | Val Loss: 0.0170\n",
      "Epoch 88/500 | Train Loss: 0.0156 | Val Loss: 0.0169\n",
      "Epoch 89/500 | Train Loss: 0.0162 | Val Loss: 0.0169\n",
      "Epoch 90/500 | Train Loss: 0.0154 | Val Loss: 0.0169\n",
      "Epoch 91/500 | Train Loss: 0.0156 | Val Loss: 0.0169\n",
      "Epoch 92/500 | Train Loss: 0.0166 | Val Loss: 0.0167\n",
      "Epoch 93/500 | Train Loss: 0.0152 | Val Loss: 0.0168\n",
      "Epoch 94/500 | Train Loss: 0.0157 | Val Loss: 0.0167\n",
      "Epoch 95/500 | Train Loss: 0.0162 | Val Loss: 0.0166\n",
      "Epoch 96/500 | Train Loss: 0.0155 | Val Loss: 0.0166\n",
      "Epoch 97/500 | Train Loss: 0.0160 | Val Loss: 0.0167\n",
      "Epoch 98/500 | Train Loss: 0.0154 | Val Loss: 0.0165\n",
      "Epoch 99/500 | Train Loss: 0.0160 | Val Loss: 0.0165\n",
      "Epoch 100/500 | Train Loss: 0.0159 | Val Loss: 0.0165\n",
      "Epoch 101/500 | Train Loss: 0.0148 | Val Loss: 0.0165\n",
      "Epoch 102/500 | Train Loss: 0.0151 | Val Loss: 0.0165\n",
      "Epoch 103/500 | Train Loss: 0.0154 | Val Loss: 0.0165\n",
      "Epoch 104/500 | Train Loss: 0.0155 | Val Loss: 0.0164\n",
      "Epoch 105/500 | Train Loss: 0.0153 | Val Loss: 0.0164\n",
      "Epoch 106/500 | Train Loss: 0.0149 | Val Loss: 0.0164\n",
      "Epoch 107/500 | Train Loss: 0.0159 | Val Loss: 0.0165\n",
      "Epoch 108/500 | Train Loss: 0.0149 | Val Loss: 0.0164\n",
      "Epoch 109/500 | Train Loss: 0.0151 | Val Loss: 0.0163\n",
      "Epoch 110/500 | Train Loss: 0.0152 | Val Loss: 0.0164\n",
      "Epoch 111/500 | Train Loss: 0.0149 | Val Loss: 0.0163\n",
      "Epoch 112/500 | Train Loss: 0.0150 | Val Loss: 0.0163\n",
      "Epoch 113/500 | Train Loss: 0.0151 | Val Loss: 0.0164\n",
      "Epoch 114/500 | Train Loss: 0.0145 | Val Loss: 0.0164\n",
      "Epoch 115/500 | Train Loss: 0.0147 | Val Loss: 0.0163\n",
      "Epoch 116/500 | Train Loss: 0.0146 | Val Loss: 0.0161\n",
      "Epoch 117/500 | Train Loss: 0.0147 | Val Loss: 0.0161\n",
      "Epoch 118/500 | Train Loss: 0.0148 | Val Loss: 0.0161\n",
      "Epoch 119/500 | Train Loss: 0.0150 | Val Loss: 0.0160\n",
      "Epoch 120/500 | Train Loss: 0.0142 | Val Loss: 0.0159\n",
      "Epoch 121/500 | Train Loss: 0.0148 | Val Loss: 0.0159\n",
      "Epoch 122/500 | Train Loss: 0.0145 | Val Loss: 0.0159\n",
      "Epoch 123/500 | Train Loss: 0.0144 | Val Loss: 0.0159\n",
      "Epoch 124/500 | Train Loss: 0.0144 | Val Loss: 0.0158\n",
      "Epoch 125/500 | Train Loss: 0.0141 | Val Loss: 0.0158\n",
      "Epoch 126/500 | Train Loss: 0.0140 | Val Loss: 0.0158\n",
      "Epoch 127/500 | Train Loss: 0.0143 | Val Loss: 0.0157\n",
      "Epoch 128/500 | Train Loss: 0.0146 | Val Loss: 0.0157\n",
      "Epoch 129/500 | Train Loss: 0.0144 | Val Loss: 0.0157\n",
      "Epoch 130/500 | Train Loss: 0.0143 | Val Loss: 0.0157\n",
      "Epoch 131/500 | Train Loss: 0.0139 | Val Loss: 0.0156\n",
      "Epoch 132/500 | Train Loss: 0.0144 | Val Loss: 0.0156\n",
      "Epoch 133/500 | Train Loss: 0.0143 | Val Loss: 0.0155\n",
      "Epoch 134/500 | Train Loss: 0.0143 | Val Loss: 0.0155\n",
      "Epoch 135/500 | Train Loss: 0.0140 | Val Loss: 0.0155\n",
      "Epoch 136/500 | Train Loss: 0.0138 | Val Loss: 0.0155\n",
      "Epoch 137/500 | Train Loss: 0.0142 | Val Loss: 0.0155\n",
      "Epoch 138/500 | Train Loss: 0.0138 | Val Loss: 0.0155\n",
      "Epoch 139/500 | Train Loss: 0.0142 | Val Loss: 0.0157\n",
      "Epoch 140/500 | Train Loss: 0.0140 | Val Loss: 0.0155\n",
      "Epoch 141/500 | Train Loss: 0.0147 | Val Loss: 0.0155\n",
      "Epoch 142/500 | Train Loss: 0.0143 | Val Loss: 0.0154\n",
      "Epoch 143/500 | Train Loss: 0.0141 | Val Loss: 0.0154\n",
      "Epoch 144/500 | Train Loss: 0.0140 | Val Loss: 0.0153\n",
      "Epoch 145/500 | Train Loss: 0.0138 | Val Loss: 0.0153\n",
      "Epoch 146/500 | Train Loss: 0.0136 | Val Loss: 0.0150\n",
      "Epoch 147/500 | Train Loss: 0.0138 | Val Loss: 0.0154\n",
      "Epoch 148/500 | Train Loss: 0.0145 | Val Loss: 0.0153\n",
      "Epoch 149/500 | Train Loss: 0.0138 | Val Loss: 0.0153\n",
      "Epoch 150/500 | Train Loss: 0.0140 | Val Loss: 0.0152\n",
      "Epoch 151/500 | Train Loss: 0.0139 | Val Loss: 0.0153\n",
      "Epoch 152/500 | Train Loss: 0.0139 | Val Loss: 0.0153\n",
      "Epoch 153/500 | Train Loss: 0.0140 | Val Loss: 0.0152\n",
      "Epoch 154/500 | Train Loss: 0.0138 | Val Loss: 0.0153\n",
      "Epoch 155/500 | Train Loss: 0.0137 | Val Loss: 0.0151\n",
      "Epoch 156/500 | Train Loss: 0.0138 | Val Loss: 0.0152\n",
      "Epoch 157/500 | Train Loss: 0.0136 | Val Loss: 0.0152\n",
      "Epoch 158/500 | Train Loss: 0.0134 | Val Loss: 0.0150\n",
      "Epoch 159/500 | Train Loss: 0.0140 | Val Loss: 0.0149\n",
      "Epoch 160/500 | Train Loss: 0.0133 | Val Loss: 0.0148\n",
      "Epoch 161/500 | Train Loss: 0.0140 | Val Loss: 0.0151\n",
      "Epoch 162/500 | Train Loss: 0.0134 | Val Loss: 0.0150\n",
      "Epoch 163/500 | Train Loss: 0.0138 | Val Loss: 0.0150\n",
      "Epoch 164/500 | Train Loss: 0.0136 | Val Loss: 0.0151\n",
      "Epoch 165/500 | Train Loss: 0.0136 | Val Loss: 0.0149\n",
      "Epoch 166/500 | Train Loss: 0.0131 | Val Loss: 0.0149\n",
      "Epoch 167/500 | Train Loss: 0.0138 | Val Loss: 0.0145\n",
      "Epoch 168/500 | Train Loss: 0.0134 | Val Loss: 0.0148\n",
      "Epoch 169/500 | Train Loss: 0.0127 | Val Loss: 0.0146\n",
      "Epoch 170/500 | Train Loss: 0.0132 | Val Loss: 0.0142\n",
      "Epoch 171/500 | Train Loss: 0.0140 | Val Loss: 0.0149\n",
      "Epoch 172/500 | Train Loss: 0.0128 | Val Loss: 0.0149\n",
      "Epoch 173/500 | Train Loss: 0.0138 | Val Loss: 0.0147\n",
      "Epoch 174/500 | Train Loss: 0.0135 | Val Loss: 0.0145\n",
      "Epoch 175/500 | Train Loss: 0.0134 | Val Loss: 0.0144\n",
      "Epoch 176/500 | Train Loss: 0.0133 | Val Loss: 0.0145\n",
      "Epoch 177/500 | Train Loss: 0.0135 | Val Loss: 0.0147\n",
      "Epoch 178/500 | Train Loss: 0.0133 | Val Loss: 0.0145\n",
      "Epoch 179/500 | Train Loss: 0.0132 | Val Loss: 0.0145\n",
      "Epoch 180/500 | Train Loss: 0.0131 | Val Loss: 0.0147\n",
      "Epoch 181/500 | Train Loss: 0.0138 | Val Loss: 0.0146\n",
      "Epoch 182/500 | Train Loss: 0.0134 | Val Loss: 0.0146\n",
      "Epoch 183/500 | Train Loss: 0.0134 | Val Loss: 0.0146\n",
      "Epoch 184/500 | Train Loss: 0.0133 | Val Loss: 0.0144\n",
      "Epoch 185/500 | Train Loss: 0.0130 | Val Loss: 0.0145\n",
      "Epoch 186/500 | Train Loss: 0.0133 | Val Loss: 0.0146\n",
      "Epoch 187/500 | Train Loss: 0.0133 | Val Loss: 0.0146\n",
      "Epoch 188/500 | Train Loss: 0.0131 | Val Loss: 0.0146\n",
      "Epoch 189/500 | Train Loss: 0.0127 | Val Loss: 0.0146\n",
      "Epoch 190/500 | Train Loss: 0.0133 | Val Loss: 0.0144\n",
      "Epoch 191/500 | Train Loss: 0.0136 | Val Loss: 0.0143\n",
      "Epoch 192/500 | Train Loss: 0.0126 | Val Loss: 0.0147\n",
      "Epoch 193/500 | Train Loss: 0.0133 | Val Loss: 0.0145\n",
      "Epoch 194/500 | Train Loss: 0.0132 | Val Loss: 0.0142\n",
      "早停步 epoch= 195\n",
      "训练完成\n",
      "\n",
      "最佳 patience: 25 validation loss: 0.0142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# 保存初始模型和优化器状态1\n",
    "original_state = copy.deepcopy(model.state_dict())\n",
    "original_optimizer = copy.deepcopy(optimizer)  # 保存优化器配置\n",
    "\n",
    "\n",
    "# 定义网格搜索参数\n",
    "patience_values = [5,10,15,20,25]\n",
    "best_overall_val_loss = float('inf')\n",
    "best_patience = None\n",
    "best_model_state = None\n",
    "\n",
    "# 在原网格搜索循环中添加记录保存：\n",
    "patience_results = []  # 在循环前初始化\n",
    "\n",
    "for patience in patience_values:\n",
    "    print(f\"=== 网格搜索 patience={patience} ===\")\n",
    "    \n",
    "    # 重置模型和优化器状态\n",
    "    model.load_state_dict(original_state)\n",
    "    optimizer = type(original_optimizer)(model.parameters(), **original_optimizer.defaults)\n",
    "    \n",
    "    # 训练模型\n",
    "    train_losses, val_losses, best_model_outputs, best_model_labels, epoch= train_model(model, train_loader, val_loader, criterion, optimizer, epochs=500, patience=patience)\n",
    "    \n",
    "    # 获取当前最佳验证损失和模型参数\n",
    "    current_best_val_loss = min(val_losses)\n",
    "    current_model_state = torch.load('best_model.pth')  # 读取保存的最佳模型\n",
    "    \n",
    "    # 更新全局最佳结果\n",
    "    if current_best_val_loss < best_overall_val_loss:\n",
    "        best_overall_val_loss = current_best_val_loss\n",
    "        best_patience = patience\n",
    "        best_model_state = current_model_state\n",
    "\n",
    "\n",
    "    # 保存完整记录\n",
    "    patience_results.append({\n",
    "        'patience': patience,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'best_val_loss': current_best_val_loss\n",
    "    })\n",
    "    \n",
    "# 保存最终最佳模型\n",
    "torch.save(best_model_state, 'best_model_grid_search.pth')\n",
    "print(f\"\\n最佳 patience: {best_patience} validation loss: {best_overall_val_loss:.4f}\")\n",
    "\n",
    "# 加载最佳模型进行后续使用\n",
    "model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 画图（基于最佳早停参数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_curves(train_losses, val_losses, best_patience):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 绘制训练损失（实线）\n",
    "    plt.plot(train_losses, \n",
    "             label='Training Loss',\n",
    "             linestyle='-',\n",
    "             color='blue',\n",
    "            )\n",
    "    \n",
    "    # 绘制验证损失（虚线）\n",
    "    plt.plot(val_losses,\n",
    "             label='Validation Loss',\n",
    "             linestyle='--',\n",
    "             color='red'\n",
    "            )  # 自定义虚线样式\n",
    "    \n",
    "    # 标注最佳patience参数\n",
    "    plt.title(f'Loss Curves (Best Patience={best_patience})')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 添加网格线\n",
    "    plt.grid(True, alpha=0.3, linestyle=':')\n",
    "    \n",
    "    # 自动调整刻度范围\n",
    "    max_epoch = max(len(train_losses), len(val_losses))\n",
    "    plt.xlim(0, max_epoch-1)\n",
    "    \n",
    "    plt.text(0.8, 0.2, f\"epoch = {epoch+1}\", transform=plt.gca().transAxes, fontsize=15)\n",
    "\n",
    "# 从保存结果中获取最佳参数对应的损失曲线\n",
    "best_train = []\n",
    "best_val = []\n",
    "for result in patience_results:\n",
    "    if result['patience'] == best_patience:\n",
    "        best_train = result['train_losses']\n",
    "        best_val = result['val_losses']\n",
    "        break\n",
    "\n",
    "# 调用绘图函数\n",
    "plot_loss_curves(best_train, best_val, best_patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用测试集评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.09401709401709402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         FCC       0.93      0.94      0.94        70\n",
      "         BCC       0.91      0.95      0.93        61\n",
      "          IM       0.74      0.84      0.79        51\n",
      "          AM       0.50      0.67      0.57         3\n",
      "\n",
      "   micro avg       0.86      0.91      0.88       185\n",
      "   macro avg       0.77      0.85      0.81       185\n",
      "weighted avg       0.86      0.91      0.89       185\n",
      " samples avg       0.89      0.93      0.89       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 加载最佳模型权重\n",
    "model.load_state_dict(torch.load('best_model_grid_search.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        y_pred.extend(outputs.numpy() > 0.5)  # 概率阈值设为0.5\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "# 计算指标\n",
    "print(\"Hamming Loss:\", hamming_loss(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred, target_names=[\"FCC\", \"BCC\", \"IM\", \"AM\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测新数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\联想\\AppData\\Local\\Temp\\ipykernel_5560\\2016536570.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ele] = 0\n",
      "C:\\Users\\联想\\AppData\\Local\\Temp\\ipykernel_5560\\2016536570.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ele] = 0\n",
      "C:\\Users\\联想\\AppData\\Local\\Temp\\ipykernel_5560\\2016536570.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ele] = 0\n",
      "C:\\Users\\联想\\AppData\\Local\\Temp\\ipykernel_5560\\2016536570.py:20: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df[reorder].applymap(lambda x: x * 0.01)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open(\"alloy_selected.csv\",\"r\",encoding=\"utf-8\") as f:\n",
    "    df_origin=pd.read_csv(f) \n",
    "\n",
    "#带化学式\n",
    "df_formula=df_origin[[\"Co\",\"Cr\",\"Fe\",\"Mn\",\"Ni\",\"V\",\"formula\"]]\n",
    "\n",
    "#不带化学式\n",
    "df=df_origin[[\"Co\",\"Cr\",\"Fe\",\"Mn\",\"Ni\",\"V\"]]\n",
    "\n",
    "# 为0元素列\n",
    "features = ['Al','Si', 'Mo', 'Ti', 'Cu', 'Zr','Nb', 'Sn', 'Zn', 'Ta', 'Hf', 'W', 'B','C']\n",
    "\n",
    "for ele in features:\n",
    "    df[ele] = 0\n",
    "\n",
    "reorder = ['Al', 'Co', 'Fe', 'Ni', 'Si', 'Mn', 'Cr','Mo', 'Ti', 'Cu', 'Zr', 'V', 'Nb', 'Sn', 'Zn', 'Ta', 'Hf', 'W', 'B','C']\n",
    "#成分小数化\n",
    "df = df[reorder].applymap(lambda x: x * 0.01)\n",
    "\n",
    "new_data = df.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 验证集判断全局阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Global Threshold: 0.5300 (Macro F1=0.8891)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 加载最佳模型，调整全局阈值\n",
    "model.load_state_dict(torch.load('best_model_grid_search.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 计算最优阈值\n",
    "def find_optimal_threshold(outputs, labels):\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0.0\n",
    "    thresholds = np.arange(0.01, 0.99, 0.01)  # 候选阈值范围\n",
    "    for th in thresholds:\n",
    "        preds = (outputs > th).float()\n",
    "        f1 = f1_score(labels.numpy(), preds.numpy(), average='macro')  # 宏平均F1\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = th\n",
    "    return best_threshold,best_f1\n",
    "\n",
    "best_threshold,best_f1 = find_optimal_threshold(best_model_outputs, best_model_labels)\n",
    "print(f\"Optimal Global Threshold: {best_threshold:.4f} (Macro F1={best_f1:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9999e-01, 2.9245e-03, 4.0528e-02, 7.3822e-04],\n",
      "        [9.9995e-01, 1.5044e-03, 3.5190e-01, 3.2468e-07],\n",
      "        [9.9993e-01, 5.4059e-03, 9.3490e-02, 1.4659e-05],\n",
      "        [9.9997e-01, 1.1611e-03, 2.4562e-01, 9.1342e-08],\n",
      "        [9.9998e-01, 4.4852e-03, 5.1549e-02, 2.5153e-05],\n",
      "        [9.9991e-01, 5.7848e-03, 1.0160e-01, 1.8801e-05],\n",
      "        [9.9349e-01, 5.1108e-02, 1.9171e-01, 7.2808e-10],\n",
      "        [9.9995e-01, 6.0282e-03, 6.6899e-02, 1.3302e-05],\n",
      "        [9.9999e-01, 3.7471e-03, 5.2601e-02, 1.0918e-03],\n",
      "        [9.9643e-01, 3.2399e-02, 1.9710e-01, 1.3797e-09],\n",
      "        [9.9998e-01, 1.0330e-03, 2.1851e-01, 2.1546e-07],\n",
      "        [1.0000e+00, 2.3806e-03, 4.3930e-02, 4.9940e-04],\n",
      "        [9.9997e-01, 1.2297e-03, 2.5281e-01, 1.5251e-07],\n",
      "        [9.9873e-01, 1.8522e-02, 1.7115e-01, 1.8785e-09],\n",
      "        [9.9996e-01, 1.3979e-03, 3.1961e-01, 2.3484e-07],\n",
      "        [9.9881e-01, 1.6225e-02, 1.8293e-01, 1.9287e-09],\n",
      "        [9.9999e-01, 3.1094e-03, 4.5172e-02, 8.6676e-04],\n",
      "        [1.0000e+00, 2.5177e-03, 3.0691e-02, 3.7260e-04],\n",
      "        [9.9995e-01, 5.0182e-03, 7.2841e-02, 6.1329e-06],\n",
      "        [9.9985e-01, 7.8231e-03, 1.1030e-01, 1.8672e-05],\n",
      "        [9.9994e-01, 1.6560e-03, 4.0930e-01, 8.8431e-07],\n",
      "        [9.9999e-01, 3.3732e-03, 4.2171e-02, 7.9966e-04],\n",
      "        [9.9998e-01, 1.0494e-03, 2.2881e-01, 1.5313e-07],\n",
      "        [9.9994e-01, 1.6457e-03, 3.8489e-01, 4.5084e-07],\n",
      "        [9.9997e-01, 1.1487e-03, 2.4574e-01, 9.0869e-08],\n",
      "        [9.9998e-01, 1.0723e-03, 2.2864e-01, 1.5460e-07],\n",
      "        [9.9990e-01, 1.8497e-03, 4.9218e-01, 1.5996e-06],\n",
      "        [9.9997e-01, 1.2771e-03, 2.6581e-01, 1.0444e-07],\n",
      "        [1.0000e+00, 3.1166e-03, 3.0401e-02, 4.6082e-04],\n",
      "        [1.0000e+00, 2.6605e-03, 3.3079e-02, 4.7766e-04],\n",
      "        [9.9995e-01, 5.1787e-03, 7.5930e-02, 9.5601e-06],\n",
      "        [9.9995e-01, 1.4837e-03, 3.2443e-01, 1.9806e-07],\n",
      "        [9.9990e-01, 6.2831e-03, 9.7698e-02, 1.0568e-05],\n",
      "        [9.9998e-01, 1.1060e-03, 2.3898e-01, 2.5498e-07],\n",
      "        [9.9769e-01, 2.5500e-02, 1.8136e-01, 7.9837e-10],\n",
      "        [9.9785e-01, 2.5238e-02, 1.7266e-01, 5.0394e-10],\n",
      "        [9.9998e-01, 3.9688e-03, 6.1010e-02, 1.4805e-05],\n",
      "        [9.9998e-01, 1.0972e-03, 2.3402e-01, 3.0395e-07],\n",
      "        [9.9993e-01, 6.2494e-03, 8.2530e-02, 2.0427e-05],\n",
      "        [9.9987e-01, 8.0308e-03, 9.7476e-02, 2.9532e-05],\n",
      "        [9.9791e-01, 2.1772e-02, 1.9842e-01, 1.5283e-09],\n",
      "        [9.9999e-01, 2.5802e-03, 4.5240e-02, 7.1966e-04],\n",
      "        [9.8519e-01, 6.4291e-02, 2.5578e-01, 1.5774e-09],\n",
      "        [9.9987e-01, 2.0689e-03, 5.0626e-01, 9.1469e-07],\n",
      "        [9.9876e-01, 1.6725e-02, 1.7848e-01, 1.0358e-09],\n",
      "        [9.9975e-01, 9.3704e-03, 1.3677e-01, 4.8168e-05],\n",
      "        [9.9999e-01, 1.0024e-03, 2.1325e-01, 2.5185e-07],\n",
      "        [9.9991e-01, 6.6409e-03, 8.9820e-02, 1.3834e-05],\n",
      "        [9.9993e-01, 1.6980e-03, 4.1482e-01, 7.3102e-07],\n",
      "        [9.9995e-01, 6.1112e-03, 6.6611e-02, 2.5259e-05]])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Co</th>\n",
       "      <th>Cr</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Mn</th>\n",
       "      <th>Ni</th>\n",
       "      <th>V</th>\n",
       "      <th>formula</th>\n",
       "      <th>FCC</th>\n",
       "      <th>BCC</th>\n",
       "      <th>IM</th>\n",
       "      <th>AM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.24Cr0.24Mn0.25Ni0.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.24Cr0.23Fe0.26Ni0.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.25Fe0.26Mn0.23Ni0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.28Cr0.26Fe0.26Ni0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.28Fe0.20Mn0.25Ni0.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.24Fe0.26Mn0.23Ni0.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>Co0.25Fe0.24Ni0.26V0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.27Fe0.25Mn0.26Ni0.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.21Cr0.24Mn0.27Ni0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>Co0.25Fe0.25Ni0.27V0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.28Cr0.28Fe0.21Ni0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.25Cr0.27Mn0.20Ni0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.27Cr0.28Fe0.25Ni0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>Co0.27Fe0.24Ni0.28V0.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.25Cr0.22Fe0.26Ni0.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>Co0.27Fe0.26Ni0.27V0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.23Cr0.25Mn0.25Ni0.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.27Cr0.23Mn0.24Ni0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.28Fe0.27Mn0.24Ni0.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.23Fe0.28Mn0.25Ni0.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.22Cr0.28Fe0.24Ni0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.23Cr0.24Mn0.27Ni0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.28Cr0.22Fe0.23Ni0.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.23Cr0.27Fe0.26Ni0.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.28Cr0.24Fe0.26Ni0.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.28Cr0.26Fe0.23Ni0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.20Cr0.28Fe0.24Ni0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.27Cr0.25Fe0.27Ni0.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.26Cr0.22Mn0.28Ni0.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.26Cr0.21Mn0.25Ni0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.27Fe0.26Mn0.24Ni0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.25Cr0.28Fe0.27Ni0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.25Fe0.28Mn0.24Ni0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.27Cr0.23Fe0.22Ni0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>Co0.27Fe0.27Ni0.24V0.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>Co0.28Fe0.28Ni0.22V0.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.28Fe0.22Mn0.23Ni0.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.27Cr0.26Fe0.21Ni0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.25Fe0.25Mn0.25Ni0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.23Fe0.26Mn0.26Ni0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>Co0.26Fe0.27Ni0.26V0.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.24Cr0.26Mn0.22Ni0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>Co0.21Fe0.26Ni0.28V0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.20Cr0.28Fe0.27Ni0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>Co0.28Fe0.28Ni0.24V0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.20Fe0.27Mn0.25Ni0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.28Cr0.26Fe0.20Ni0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.25Fe0.27Mn0.25Ni0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.22Cr0.26Fe0.25Ni0.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>Co0.26Fe0.23Mn0.26Ni0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Co  Cr  Fe  Mn  Ni   V                   formula FCC BCC IM AM\n",
       "0   24  24   0  25  27   0  Co0.24Cr0.24Mn0.25Ni0.27   1   0  0  0\n",
       "1   24  23  26   0  27   0  Co0.24Cr0.23Fe0.26Ni0.27   1   0  0  0\n",
       "2   25   0  26  23  26   0  Co0.25Fe0.26Mn0.23Ni0.26   1   0  0  0\n",
       "3   28  26  26   0  20   0  Co0.28Cr0.26Fe0.26Ni0.20   1   0  0  0\n",
       "4   28   0  20  25  27   0  Co0.28Fe0.20Mn0.25Ni0.27   1   0  0  0\n",
       "5   24   0  26  23  27   0  Co0.24Fe0.26Mn0.23Ni0.27   1   0  0  0\n",
       "6   25   0  24   0  26  25   Co0.25Fe0.24Ni0.26V0.25   1   0  0  0\n",
       "7   27   0  25  26  22   0  Co0.27Fe0.25Mn0.26Ni0.22   1   0  0  0\n",
       "8   21  24   0  27  28   0  Co0.21Cr0.24Mn0.27Ni0.28   1   0  0  0\n",
       "9   25   0  25   0  27  23   Co0.25Fe0.25Ni0.27V0.23   1   0  0  0\n",
       "10  28  28  21   0  23   0  Co0.28Cr0.28Fe0.21Ni0.23   1   0  0  0\n",
       "11  25  27   0  20  28   0  Co0.25Cr0.27Mn0.20Ni0.28   1   0  0  0\n",
       "12  27  28  25   0  20   0  Co0.27Cr0.28Fe0.25Ni0.20   1   0  0  0\n",
       "13  27   0  24   0  28  21   Co0.27Fe0.24Ni0.28V0.21   1   0  0  0\n",
       "14  25  22  26   0  27   0  Co0.25Cr0.22Fe0.26Ni0.27   1   0  0  0\n",
       "15  27   0  26   0  27  20   Co0.27Fe0.26Ni0.27V0.20   1   0  0  0\n",
       "16  23  25   0  25  27   0  Co0.23Cr0.25Mn0.25Ni0.27   1   0  0  0\n",
       "17  27  23   0  24  26   0  Co0.27Cr0.23Mn0.24Ni0.26   1   0  0  0\n",
       "18  28   0  27  24  21   0  Co0.28Fe0.27Mn0.24Ni0.21   1   0  0  0\n",
       "19  23   0  28  25  24   0  Co0.23Fe0.28Mn0.25Ni0.24   1   0  0  0\n",
       "20  22  28  24   0  26   0  Co0.22Cr0.28Fe0.24Ni0.26   1   0  0  0\n",
       "21  23  24   0  27  26   0  Co0.23Cr0.24Mn0.27Ni0.26   1   0  0  0\n",
       "22  28  22  23   0  27   0  Co0.28Cr0.22Fe0.23Ni0.27   1   0  0  0\n",
       "23  23  27  26   0  24   0  Co0.23Cr0.27Fe0.26Ni0.24   1   0  0  0\n",
       "24  28  24  26   0  22   0  Co0.28Cr0.24Fe0.26Ni0.22   1   0  0  0\n",
       "25  28  26  23   0  23   0  Co0.28Cr0.26Fe0.23Ni0.23   1   0  0  0\n",
       "26  20  28  24   0  28   0  Co0.20Cr0.28Fe0.24Ni0.28   1   0  0  0\n",
       "27  27  25  27   0  21   0  Co0.27Cr0.25Fe0.27Ni0.21   1   0  0  0\n",
       "28  26  22   0  28  24   0  Co0.26Cr0.22Mn0.28Ni0.24   1   0  0  0\n",
       "29  26  21   0  25  28   0  Co0.26Cr0.21Mn0.25Ni0.28   1   0  0  0\n",
       "30  27   0  26  24  23   0  Co0.27Fe0.26Mn0.24Ni0.23   1   0  0  0\n",
       "31  25  28  27   0  20   0  Co0.25Cr0.28Fe0.27Ni0.20   1   0  0  0\n",
       "32  25   0  28  24  23   0  Co0.25Fe0.28Mn0.24Ni0.23   1   0  0  0\n",
       "33  27  23  22   0  28   0  Co0.27Cr0.23Fe0.22Ni0.28   1   0  0  0\n",
       "34  27   0  27   0  24  22   Co0.27Fe0.27Ni0.24V0.22   1   0  0  0\n",
       "35  28   0  28   0  22  22   Co0.28Fe0.28Ni0.22V0.22   1   0  0  0\n",
       "36  28   0  22  23  27   0  Co0.28Fe0.22Mn0.23Ni0.27   1   0  0  0\n",
       "37  27  26  21   0  26   0  Co0.27Cr0.26Fe0.21Ni0.26   1   0  0  0\n",
       "38  25   0  25  25  25   0  Co0.25Fe0.25Mn0.25Ni0.25   1   0  0  0\n",
       "39  23   0  26  26  25   0  Co0.23Fe0.26Mn0.26Ni0.25   1   0  0  0\n",
       "40  26   0  27   0  26  21   Co0.26Fe0.27Ni0.26V0.21   1   0  0  0\n",
       "41  24  26   0  22  28   0  Co0.24Cr0.26Mn0.22Ni0.28   1   0  0  0\n",
       "42  21   0  26   0  28  25   Co0.21Fe0.26Ni0.28V0.25   1   0  0  0\n",
       "43  20  28  27   0  25   0  Co0.20Cr0.28Fe0.27Ni0.25   1   0  0  0\n",
       "44  28   0  28   0  24  20   Co0.28Fe0.28Ni0.24V0.20   1   0  0  0\n",
       "45  20   0  27  25  28   0  Co0.20Fe0.27Mn0.25Ni0.28   1   0  0  0\n",
       "46  28  26  20   0  26   0  Co0.28Cr0.26Fe0.20Ni0.26   1   0  0  0\n",
       "47  25   0  27  25  23   0  Co0.25Fe0.27Mn0.25Ni0.23   1   0  0  0\n",
       "48  22  26  25   0  27   0  Co0.22Cr0.26Fe0.25Ni0.27   1   0  0  0\n",
       "49  26   0  23  26  25   0  Co0.26Fe0.23Mn0.26Ni0.25   1   0  0  0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型\n",
    "model = phaseclassifier(input_size=X_train.shape[1],output_size=y_train.shape[1])\n",
    "model.load_state_dict(torch.load('best_model_grid_search.pth'))\n",
    "\n",
    "#归一化\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "new_data_tensor = torch.tensor(new_data_scaled, dtype=torch.float32)    #一般模型的输入x为数组，神经网络的输入x为张量\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model(new_data_tensor).numpy() > best_threshold  # 阈值\n",
    "    print(model(new_data_tensor))\n",
    "\n",
    "# 遍历每个样本的预测结果\n",
    "predicted_phases_list = []\n",
    "for sample_pred in prediction:  # sample_pred 是单个样本的4个预测标签\n",
    "    # 获取当前样本中为 True 的索引\n",
    "    sample_indices = np.where(sample_pred)[0]\n",
    "    # 根据索引提取相名称\n",
    "    sample_phases = [[\"FCC\", \"BCC\", \"IM\", \"AM\"][i] for i in sample_indices]\n",
    "    predicted_phases_list.append(sample_phases)\n",
    "\n",
    "\n",
    "# 定义相的顺序\n",
    "phases = [\"FCC\", \"BCC\", \"IM\", \"AM\"]\n",
    "\n",
    "# 生成每行的0/1数据\n",
    "data = []\n",
    "for sample_phases in predicted_phases_list:\n",
    "    row = [1 if phase in sample_phases else 0 for phase in phases]\n",
    "    data.append(row)\n",
    "\n",
    "# 创建DataFrame\n",
    "df_predicted = pd.DataFrame(data, columns=phases)\n",
    "#print(df)\n",
    "\n",
    "array_output = np.concatenate((df_formula, df_predicted), axis=1)\n",
    "df_output=pd.DataFrame(array_output,columns=[\"Co\",\"Cr\",\"Fe\",\"Mn\",\"Ni\",\"V\",\"formula\",\"FCC\", \"BCC\", \"IM\", \"AM\"])\n",
    "df_output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
